[
  {
    "objectID": "setup/workshop_setup.html",
    "href": "setup/workshop_setup.html",
    "title": "Cloud Workspace Setup",
    "section": "",
    "text": "If you plan to use this repository with the Openscapes 2i2c JupyterHub Cloud Workspace there are no additional setup requirements for the Python environment. All packages needed are included unless specified within a notebook, in which case a cell will be dedicated to installing the necessary Python libraries using the appropriate package manager.\nAfter completing the prerequisites you will have access to the Openscapes 2i2c JupyterHub cloud workspace. Click here to start JupyterLab. Use your email and the provided password to sign in. This password will be provided in the workshop. If you’re interested in using the 2i2c cloud workspace outside of the workshop, please contact us.\nAfter signing in you will be prompted for some server options:\nSelect the following options:",
    "crumbs": [
      "Setup Instructions",
      "Cloud Workspace Setup"
    ]
  },
  {
    "objectID": "setup/workshop_setup.html#cloning-the-neon-and-nasa-repositories",
    "href": "setup/workshop_setup.html#cloning-the-neon-and-nasa-repositories",
    "title": "Cloud Workspace Setup",
    "section": "Cloning the NEON and NASA repositories",
    "text": "Cloning the NEON and NASA repositories\nOnce the cloud workspace with the required Python environment is spun up, you can clone the repositories containing the NEON and NASA notebooks as follows.\n\nNEON Notebooks\nTo clone the repository containing the NEON notebooks, navigate to the directory where you want to store the repository on Openscapes (your home directory), then type the following from the terminal or command prompt:\ngit clone https://github.com/NEONScience/neon-nasa-hsi-workshop.git\nTo locate and start running the NEON notebooks, change directories (cd) to neon-nasa-hsi-workshop/neon\ncd neon-nasa-hsi-workshop/neon\n\n\nNASA Notebooks\nTo clone the repository containing the NASA airborne notebooks, navigate to the directory where you want to store the repository on Openscapes (your home directory)\ncd ~\nThen type the following from the terminal or command prompt:\ngit clone https://github.com/ornldaac/airborne.git\nTo find and open the NASA notebooks, change directories to where the airborne notebooks are saved:\ncd airborne/notebooks",
    "crumbs": [
      "Setup Instructions",
      "Cloud Workspace Setup"
    ]
  },
  {
    "objectID": "setup/workshop_setup.html#troubleshooting",
    "href": "setup/workshop_setup.html#troubleshooting",
    "title": "Cloud Workspace Setup",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nWe recommend Shutting down all kernels after running each notebook. This will clear the memory used by the previous notebook, and is necessary to run some of the more memory intensive notebooks.\n\n\n\nNo single notebook exceeds roughly the limit using the provided data, but if you choose to use your own data in the notebook, or have 2 notebooks open and do not shut down the kernel, you may get an out of memory error.\n\nTricks to avoid potential pitfalls\nThe notebooks in this workshop use relative paths and assume you are working from the same working directory as the instructors. If you are not finding a data file in the right path, we recommend the following troubleshooting steps to make sure you are in the right place.\n\nTo show your current working directory in Python, type into a notebook cell:\n\nimport os\nos.getcwd() # get current working directory\n\nTo display the contents (files, folders) in you current directory, use !ls. ls is a Linux command meaning list directory. You can run linux commands from a code cell directly when you add an exclamation mark (!) in front of the command.\n\n!ls # list contents of current directory\n\nYou can also install Python packages in this way (using !), for example:\n\n!pip install neonutilities # install the neonutilities Python package",
    "crumbs": [
      "Setup Instructions",
      "Cloud Workspace Setup"
    ]
  },
  {
    "objectID": "setup/workshop_setup.html#contributing",
    "href": "setup/workshop_setup.html#contributing",
    "title": "Cloud Workspace Setup",
    "section": "Contributing",
    "text": "Contributing\nIf you plan to edit or contribute to this NEON NASA Airborne Hyperspectral Workshop Repository repository, or the NEON-Data-Skills repository, we recommend following a fork and pull workflow: first fork the repository, then clone your fork to your local machine, make changes, push changes to your fork, then make a pull request back to the main repository.",
    "crumbs": [
      "Setup Instructions",
      "Cloud Workspace Setup"
    ]
  },
  {
    "objectID": "setup/prerequisites.html",
    "href": "setup/prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "Prerequisites\nTo follow along during the workshop, or to run through the notebooks contained within the repository using the Openscapes 2i2c Cloud JupyterHub (cloud workspace), the following are required. All software and accounts are free.\n\nLaptop or tablet\n\nParticipation in the exercises requires a laptop or tablet. Yes, a tablet works too! All workshop participants will have access to a 2i2c Jupyter Lab instance running in AWS us-west 2.\n\n\nEarthdata Login account\n\nCreate an Earthdata Login account (if you don’t already have one) at https://urs.earthdata.nasa.gov/users/new\nRemember your username and password; you will need them to download or access data during the workshop and beyond.\n\nNEON User accout and API token\n\nCreate a NEON User account (if you don’t already have one) following the instructions here: https://www.neonscience.org/about/user-accounts/\nCreate an API token and save this; you will use this to download and access NEON data during the workshop and beyond. More detailed instructions on creating an API token can be found here: https://www.neonscience.org/resources/learning-hub/tutorials/neon-api-tokens-tutorial\nNote: you can also sign up for Data Notifications when you create your NEON User account. This will allow you to receive email notifications about updates or issues related to NEON data products of interest.",
    "crumbs": [
      "Setup Instructions",
      "Prerequisites"
    ]
  },
  {
    "objectID": "neon-nasa.html",
    "href": "neon-nasa.html",
    "title": "NEON and NASA Airborne and Field Tutorials",
    "section": "",
    "text": "Please view the NEON NASA Workshop Page for workshop details. Resources in this repository have been developed using the Openscapes 2i2c JupyterHub cloud workspace.\nWelcome to the NEON - NASA Airborne Hyperspectral Data Resources Repository! This repository provides Python Jupyter notebooks to help the community work with visible to short-wave infrared (VSWIR) imaging spectroscopy data from NEON’s Airborne Observation Platform and missions carried out with the NASA AVIRIS sensors. These complimentary hyperspectral datasets provide an opportunity to conduct ecological research at large scales, and also can be paired with complimentary satellite datasets such as the EMIT (Earth Surface Mineral Dust Source Investigation) and future SBG (Surface Biology and Geology) VSWIR sensor.\nIn the interest of open science, this repository has been made public, but is still under active development. Contributions from all parties are welcome.",
    "crumbs": [
      "Welcome",
      "Repository Description"
    ]
  },
  {
    "objectID": "neon-nasa.html#contact-info",
    "href": "neon-nasa.html#contact-info",
    "title": "NEON and NASA Airborne and Field Tutorials",
    "section": "Contact Info",
    "text": "Contact Info\n\nNEON AOP\n\n\n\nOrganization\nNational Ecological Observatory Network Airborne Observation Platform (NEON AOP)1\n\n\nWebsite\nhttps://neonscience.org/\n\n\nContact\nhttps://www.neonscience.org/about/contact-us/\n\n\n\n1NEON is a project fully funded by the National Science Foundation and operated by Battelle.\n\n\nORNL DAAC\n\n\n\nOrganization\nNASA Earthdata Data Center, Oak Ridge National Laboratory Distributed Active Archive Center (ORNL DAAC)\n\n\nWebsite\nhttps://www.earthdata.nasa.gov/centers/ornl-daac\n\n\nContact\nNASA Earthdata Forum: https://forum.earthdata.nasa.gov/",
    "crumbs": [
      "Welcome",
      "Repository Description"
    ]
  },
  {
    "objectID": "neon/01_make-classification-training-df.html",
    "href": "neon/01_make-classification-training-df.html",
    "title": "Make Training Data for Species Modeling from NEON TOS Vegetation Structure Data",
    "section": "",
    "text": "This notebook demonstrates how to generate a training dataset consisting of tree species, family, and location from the NEON Terrestrial Observation System (TOS) Vegetation Structure data product DP1.10098.001. We will use data from the Smithsonian Environmental Research Center (SERC) site in Maryland. In a subsequent tutorial titled Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray, we will use this training dataset to train a random forest machine learning model that predicts tree families from the hyperspectral signatures obtained from the airborne remote sensing data. These two tutorials outline a relatively simple modeling example, and represent a starting point for conducting machine learning analyses using NEON data!\n\n\nTo run this notebook, you will need the following Python packages, which can be installed using !pip install or !conda install from within the notebook. Note that to use the neonutilities package, you will need Python version 3.9 or higher.\n\nmatplotlib\nneonutilities\nnumpy\npandas\nrequests\nseaborn\n\n\n\n\n\nNEON API Token (optional, but strongly recommended), see NEON API Tokens Tutorial for more details on how to create and set up your token in Python (and R). Once you create your token (on the NEON User Accounts) page, this notebook will show you how to set it as an environment variable and use it for downloading AOP data.\n\n\n\n\n\nUse the neonutilities load_by_product function to read in NEON vegetation structure data at a given site\nUse the NEON locations API to determine the geographic position of the vegetation records in UTM x, y coordinates\nFilter the datset to include only the latest data and columns of interest\nFilter the data geospatially to keep data that are within a single AOP 1 km x 1 km tile\n\nDisclaimer: this notebook is intended to provide an example of how to create an initial training data set for pairing with remote sensing data, and to conduct some exploratory analysis of the vegetation structure data. This does not incorporate outlier detection and removal, or comprehensive pre-processing steps. As part of creating a machine learning model, it is important to assess the training data quality and look for outliers or other potential data quality issues which may impact model results. Refer to the Compare tree height measured from the ground to a Lidar-based Canopy Height Model lesson (the first additional resource above) for more details on how you would address geographic mismatch between the AOP and TOS data.\n\n\n\n\nThe lesson Compare tree height measured from the ground to a Lidar-based Canopy Height Model is another example of linking ground to airborne data, and shows similar steps of pre-processing TOS woody vegetation data.\nThe paper Individual canopy tree species maps for the National Ecological Observatory Network outlines methods for large-scale classification using NEON data. The associated NEON Science Seminar Harnessing NEON to enable the future of forest remote sensing may be a useful resource. This talk provides a high-level overview of modeling approaches for tree crown delineation and tree classification using NEON airborne remote sensing data. You can also watch the video below.\n\n\n\n\n\nRefer to the Vegetation Structure User Guide for more details on this data product, and to better understand the data quality flags, the sampling.",
    "crumbs": [
      "Tutorials",
      "1 NEON - Make a Training Dataset from Vegetation Structure Data"
    ]
  },
  {
    "objectID": "neon/01_make-classification-training-df.html#download-and-explore-vegetation-structure-data-dp1.10098.001",
    "href": "neon/01_make-classification-training-df.html#download-and-explore-vegetation-structure-data-dp1.10098.001",
    "title": "Make Training Data for Species Modeling from NEON TOS Vegetation Structure Data",
    "section": "1. Download and Explore Vegetation Structure Data (DP1.10098.001)",
    "text": "1. Download and Explore Vegetation Structure Data (DP1.10098.001)\nIn this first section we’ll load the vegetation structure data, find the locations of the mapped trees, and join to the species and family observations.\nLet’s get started! First, import the required Python packages.\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport neonutilities as nu\nimport numpy as np\nimport pandas as pd\nimport requests\nimport seaborn as sns\n\nSet up your NEON token. See the setup instructions at the beginning of the tutorial on how to set up a NEON user account and create a token, if you have not already done so.\n\n# copy and paste your NEON token from your NEON user account page here\nmy_token=\"\"\n\nWe can load the vegetation structure data using the load_by_product function in the neonutilities package (imported as nu). Inputs to the function can be shown by typing help(load_by_product).\nRefer tot e R neonUtilities cheat sheet or teh Python neonutilities documentationNEON Locations API.\n\neasting = []\nnorthing = []\ncoord_uncertainty = []\nelev_uncertainty = []\nfor i in veg_points:\n    vres = requests.get(\"https://data.neonscience.org/api/v0/locations/\"+i)\n    vres_json = vres.json()\n    easting.append(vres_json[\"data\"][\"locationUtmEasting\"])\n    northing.append(vres_json[\"data\"][\"locationUtmNorthing\"])\n    props = pd.DataFrame.from_dict(vres_json[\"data\"][\"locationProperties\"])\n    cu = props.loc[props[\"locationPropertyName\"]==\"Value for Coordinate uncertainty\"][\"locationPropertyValue\"]\n    coord_uncertainty.append(cu[cu.index[0]])\n    eu = props.loc[props[\"locationPropertyName\"]==\"Value for Elevation uncertainty\"][\"locationPropertyValue\"]\n    elev_uncertainty.append(eu[eu.index[0]])\n\npt_dict = dict(points=veg_points, \n               easting=easting,\n               northing=northing,\n               coordinateUncertainty=coord_uncertainty,\n               elevationUncertainty=elev_uncertainty)\n\npt_df = pd.DataFrame.from_dict(pt_dict)\npt_df.set_index(\"points\", inplace=True)\n\nveg_map = veg_map.join(pt_df, \n                     on=\"points\", \n                     how=\"inner\")\n\nNext, use the stemDistance and stemAzimuth data to calculate the precise locations of individuals, relative to the reference locations.\n\n\\(Easting = easting.pointID + stemDistance*sin(\\theta)\\)\n\\(Northing = northing.pointID + stemDistance*cos(\\theta)\\)\n\\(\\theta = stemAzimuth*\\pi/180\\)\n\nAlso adjust the coordinate and elevation uncertainties.\n\nveg_map[\"adjEasting\"] = (veg_map[\"easting\"]\n                        + veg_map[\"stemDistance\"]\n                        * np.sin(veg_map[\"stemAzimuth\"]\n                                   * np.pi / 180))\n\nveg_map[\"adjNorthing\"] = (veg_map[\"northing\"]\n                        + veg_map[\"stemDistance\"]\n                        * np.cos(veg_map[\"stemAzimuth\"]\n                                   * np.pi / 180))\n\nveg_map[\"adjCoordinateUncertainty\"] = veg_map[\"coordinateUncertainty\"] + 0.6\n\nveg_map[\"adjElevationUncertainty\"] = veg_map[\"elevationUncertainty\"] + 1\n\nLook at the columns to see all the information contained in this dataset.\n\n# look at a subset of the columns that may be relevant\nveg_map[['date','individualID','scientificName','taxonID','family','plotID','pointID','adjEasting','adjNorthing']].head(5)\n\n\nlen(veg_map)",
    "crumbs": [
      "Tutorials",
      "1 NEON - Make a Training Dataset from Vegetation Structure Data"
    ]
  },
  {
    "objectID": "neon/01_make-classification-training-df.html#filter-to-trees-within-an-aop-tile-extent",
    "href": "neon/01_make-classification-training-df.html#filter-to-trees-within-an-aop-tile-extent",
    "title": "Make Training Data for Species Modeling from NEON TOS Vegetation Structure Data",
    "section": "3. Filter to trees within an AOP tile extent",
    "text": "3. Filter to trees within an AOP tile extent\nNow create a new dataframe containing only the veg data that are within a single AOP tile (which are 1 km x 1 km in size). For this, you will need to know the bounds (minimum and maximum UTM easting and northing) of the area you are sampling. For this exercise, we will choose the AOP data with SW (lower left) UTM coordinates of 364000, 4305000. This tile encompasses the NEON tower at the SERC site.\n\nveg_tower_tile = veg_map[(veg_map['adjEasting'].between(364000, 365000)) & (veg_map['adjNorthing'].between(4305000, 4306000))]\n\nHow many records do we have within this tile?\n\nlen(veg_tower_tile)\n\nThere are 211 unique vegetation records in this area. We can also look at the unique taxonIDs that are represented.\n\n# look at the unique Taxon IDs\nveg_tower_tile.taxonID.unique()\n\nLet’s keep only a subset of the columns that we are interested in, and look at the dataframe:\n\nveg_tower_tile_short = veg_tower_tile[['date','individualID','scientificName','taxonID','family','adjEasting','adjNorthing']]\nveg_tower_tile_short.reset_index(drop=True, inplace=True)\nveg_tower_tile_short\n\nTo get a better sense of the data, we can also look at the # of each species, to see if some species have more representation than others.\n\n# display the taxonID counts, sorted descending\nveg_tower_tile_taxon_counts = veg_tower_tile[['individualID','taxonID']].groupby(['taxonID']).count()\nveg_tower_tile_taxon_counts.sort_values(by='individualID',ascending=False)\n\n\n# display the family counts, sorted descending\nveg_tower_tile_family_counts = veg_tower_tile[['individualID','family']].groupby(['family']).count()\nveg_tower_tile_family_counts.sort_values(by='individualID',ascending=False)\n\nIt looks like there are a number of different species (and families) mapped in this tower plot. You can use the https://plants.usda.gov website to look up the species information. The top 5 most abundant mapped species are linked below.\n\nFAGR: American Beech (Fagus grandifolia Ehrh.)\nLITU: Tuliptree (Liriodendron tulipifera L.)\nLIST2: Sweetgum (Liquidambar styraciflua L.)\nACRU: Red Maple (Acer rubrum L.)\nCAGL8: Sweet pignut hickory (Carya glabra (Mill.))\n\nWhen carrying out classification, the species that only have small representation (1-5 samples) may not be modeled accurately due to a lack of sufficient training data. The challenge of mapping rarer species due to insufficient training data is well known. In the next tutorial, we will remove these poorly represented samples before generating a model.",
    "crumbs": [
      "Tutorials",
      "1 NEON - Make a Training Dataset from Vegetation Structure Data"
    ]
  },
  {
    "objectID": "neon/01_make-classification-training-df.html#write-training-dataframe-to-csv-file",
    "href": "neon/01_make-classification-training-df.html#write-training-dataframe-to-csv-file",
    "title": "Make Training Data for Species Modeling from NEON TOS Vegetation Structure Data",
    "section": "4. Write training dataframe to csv file",
    "text": "4. Write training dataframe to csv file\nNonetheless, we have a fairly decent training dataset to work with. We can save the dataframe to a csv file called serc_training_data.csv as follows:\n\nveg_tower_tile_short.to_csv(r'./data/serc_training_data.csv',index=False)",
    "crumbs": [
      "Tutorials",
      "1 NEON - Make a Training Dataset from Vegetation Structure Data"
    ]
  },
  {
    "objectID": "neon/01_make-classification-training-df.html#plot-tree-families-in-map-view",
    "href": "neon/01_make-classification-training-df.html#plot-tree-families-in-map-view",
    "title": "Make Training Data for Species Modeling from NEON TOS Vegetation Structure Data",
    "section": "5. Plot tree families in map view",
    "text": "5. Plot tree families in map view\nFinally, we can make a quick plot using seaborn (imported as sns) to show the spatial distrubtion of the trees surveyed in this area, along with their species (scientificName). Most of this code helps improve the formatting and appearance of the figure; the first sns.scatterplot chunk is all you really need to do to plot the essentials.\n\nax = sns.scatterplot(\n    data=veg_tower_tile_short,\n    x='adjEasting',\n    y='adjNorthing',\n    hue='family',\n)\n\n# Make the x and y dimensions are equal\nax.set_aspect('equal', adjustable='box')\n\n# Remove scientific notation on the x and y axes labels\nax.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:.0f}'))\nax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda y, _: f'{y:.0f}'))\n\n# Place the legend outside the plot at the center right\nplt.legend(loc='center left', bbox_to_anchor=(1.05, 0.5))\n\n# Adjust layout to prevent legend overlap\nplt.tight_layout()\n\n# Add title and axis labels\nax.set_title(\"SERC Tree Families\", fontsize=14)\nax.set_xlabel(\"Easting (m)\", fontsize=12)\nax.set_ylabel(\"Northing (m)\", fontsize=12)\nplt.yticks(fontsize=8)  \nplt.xticks(fontsize=8)  \n\nplt.show()\n\nGreat! We can see all the trees that were surveyed in this AOP tile. The trees are sampled in discrete plots. For more information about the TOS sampling design, please refer to the Vegetation structure data product page.",
    "crumbs": [
      "Tutorials",
      "1 NEON - Make a Training Dataset from Vegetation Structure Data"
    ]
  },
  {
    "objectID": "neon/01_make-classification-training-df.html#recap",
    "href": "neon/01_make-classification-training-df.html#recap",
    "title": "Make Training Data for Species Modeling from NEON TOS Vegetation Structure Data",
    "section": "Recap",
    "text": "Recap\nIn this lesson, we have created a training data set containing information about the tree family and species as well as their geographic locations in UTM x, y coordinates. We can now pair this training data set with the remote sensing data and create a model to predict the tree’s family based off airborne spectral data. The next tutorial, Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray, will show how to do this!\nNote: you may wish to create a training dataframe that contains additional information about the trees. For example, you can also include parameters like the growth form (e.g. whether the vegetation is a shrub, single-bole or multi-bole tree, etc.), the plant status (whether the tree is healthy or standing dead), and measurements such as the stem diameter and tree height. To do this, you would need to join the vst_mappingandtagging table with the vst_apparentindividual tables. Refer to the Quick Start Guide for Vegetation Structure for more information about the data tables and the joining instructions. You can also refer to the lesson Compare tree height measured from the ground to a Lidar-based Canopy Height Model which provides an example of how to do this and compare the TOS measured data with the AOP Lidar-derived Canopy Height Model (Ecosystem Structure) data product.",
    "crumbs": [
      "Tutorials",
      "1 NEON - Make a Training Dataset from Vegetation Structure Data"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Plot to Plane: Working with NASA and NEON Airborne and Field Datasets",
    "section": "",
    "text": "NASA’s airborne science program and the NSF-funded National Ecological Observatory Network’s (NEON’s) Airborne Observation Platform (AOP) offer complementary remote sensing datasets ideal for carrying out large-scale ecological research. Both facilities operate similar airborne imaging spectrometers to collect visible to shortwave infrared (VSWIR) hyperspectral data, supporting regional ecosystem studies.\nThe Oak Ridge National Laboratory Distributed Active Archive Center (ORNL DAAC) archives data from NASA-funded ecological campaigns focusing on diverse environments such as river deltas and wetlands, the arctic, and tropics across multiple continents (North and Central America, South Africa). NEON’s AOP gathers high-resolution hyperspectral imagery, lidar, and RGB photography at 81 U.S. sites, offering repeat data spanning 2-10 years, with collections starting in 2013.\nThis workshop introduces NEON and NASA airborne and field datasets through live-coding exercises presented as Python Jupyter Notebook tutorials, demonstrating data access, exploration, and analysis. Participants will learn to apply these datasets to answer ecological research questions, gaining insights into regional and landscape areas of interest.\nThis workshop is hosted by National Ecological Observatory Network (NEON), NASA Oak Ridge National Laboratory Distributed Active Archive Center (ORNL DAAC) with support from the NASA Openscapes project.\nHands-on exercises will be executed from a Jupyter Hub on the Openscapes 2i2c cloud instance.",
    "crumbs": [
      "Welcome",
      "2025 ESA Workshop"
    ]
  },
  {
    "objectID": "index.html#agenda",
    "href": "index.html#agenda",
    "title": "Plot to Plane: Working with NASA and NEON Airborne and Field Datasets",
    "section": "Agenda",
    "text": "Agenda\n\n\n\n\n\n\n\n\nTime\nDescription\nLeads/Instructors\n\n\n\n\n8:00 AM\nIntroduction: NEON and NASA Airborne and Field Data\nBridget Hass and Michele Thornton\n\n\n8:05 AM\nOverview of NEON Airborne Observation Platform\nBridget Hass\n\n\n8:30 AM\nNEON Notebooks: Reflectance Visualization and Classification\nBridget Hass\n\n\n9:30 AM\nBreak\n\n\n\n9:35 AM\nOverview of Recent NASA Airborne Missions (SHIFT, BioSCape, AVUELO)\nMichele Thornton\n\n\n10:00 AM\nNASA Notebooks: Discovery and Analysis of VegPlot and AVIRIS Instrument Data\nMichele Thornton\n\n\n10:55 AM\nDiscussion and Wrap Up\nAll",
    "crumbs": [
      "Welcome",
      "2025 ESA Workshop"
    ]
  },
  {
    "objectID": "index.html#contact-info",
    "href": "index.html#contact-info",
    "title": "Plot to Plane: Working with NASA and NEON Airborne and Field Datasets",
    "section": "Contact Info",
    "text": "Contact Info\n\nNEON AOP\n\n\n\nOrganization\nNational Ecological Observatory Network Airborne Observation Platform (NEON AOP)1\n\n\nWebsite\nhttps://neonscience.org/\n\n\nContact\nhttps://www.neonscience.org/about/contact-us\n\n\n\n1NEON is a project fully funded by the National Science Foundation and operated by Battelle.\n\n\nORNL DAAC\n\n\n\nOrganization\nNASA Earthdata Data Center, Oak Ridge National Laboratory Distributed Active Archive Center (ORNL DAAC)\n\n\nWebsite\nhttps://www.earthdata.nasa.gov/centers/ornl-daac\n\n\nContact\nNASA Earthdata Forum: https://forum.earthdata.nasa.gov, ORNL DAAC - uso@daac.ornl.gov",
    "crumbs": [
      "Welcome",
      "2025 ESA Workshop"
    ]
  },
  {
    "objectID": "background/neon_background.html#what-is-neon",
    "href": "background/neon_background.html#what-is-neon",
    "title": "NEON Airborne and Field Datasets",
    "section": "What is NEON?",
    "text": "What is NEON?\nNEON is a continental-scale observation facility designed to collect long-term open-access ecological data to better understand the complexities of Earth’s ecosystems and how they are changing. NEON uses cutting-edge sensor networks, instrumentation, observational sampling, natural history archive facilities and remote sensing methods and technologies to collect data on plants, animals, soil, nutrients, freshwater and the atmosphere.\nNEON operates 81 field sites strategically located across 20 ecoclimatic Domains across the United States, including 47 terrestrial sites and 34 freshwater aquatic sites. When logistically possible, aquatic and terrestrial field sites are colocated (i.e. in close proximity) to support understanding of linkages across terrestrial and aquatic ecosystems and their interactions with the atmosphere. For example, Domain 08, the Ozarks Complex, has three co-located sets of terrestrial and aquatic field sites. These sites are situated along the same watershed system, creating a unique opportunity to study hydrology, nutrient transport, and biogeochemical cycling through the watershed.\n\n\n\nNEON Field Sites Map; Green: Terrestrial Sites, Blue: Aquatic Sites",
    "crumbs": [
      "Background",
      "NEON Airborne Data Background"
    ]
  },
  {
    "objectID": "background/neon_background.html#neon-airborne-observation-platform-aop",
    "href": "background/neon_background.html#neon-airborne-observation-platform-aop",
    "title": "NEON Airborne and Field Datasets",
    "section": "NEON Airborne Observation Platform (AOP)",
    "text": "NEON Airborne Observation Platform (AOP)\n\n\n\nNEON Airborne Remote Sensing\n\n\nAirborne remote sensing surveys are conducted over NEON field sites during peak greenness and provide quantitative information on land cover and changes to ecological structure and chemistry, including the presence and effects of invasive species. The surveys are supported by the NEON Airborne Observation Platform (AOP), a suite of earth observation instruments installed into a Twin Otter aircraft designed to collect high-resolution remote sensing data at low altitude. AOP was designed to collect regional-scale landscape information at the NEON field sites. The AOP maps areas where NEON’s observational and instrumented sampling is occurring and allows relationships to be drawn between NEON’s detailed in-situ observations to the broader environmental and ecological conditions.\n\nAOP Payload Sensors\nThe AOP consists of three complete and comparable instrument payloads. Typically, two of the payloads are dedicated to collections of the NEON field sites while the third is dedicated to NEON’s Research Support services which support externally driven research. The primary sensors on each payload include\n\nA discrete and full-waveform lidar to provide three-dimensional structural information of the landscape,\nAn imaging spectrometer to allow discrimination of land cover types and chemical content of vegetation,\nA high-resolution digital camera to provide spatially accurate and detailed contextual information, and\nA GPS antenna and receiver and Inertial Measurement Unit (IMU) to provide high-accuracy positioning and orientation of the aircraft.\n\n\n\nAOP Data Products\nThe AOP produces approximately 30 data products. The products are separated into categories of Level 1, Level 2, and Level 3 (L1, L2, L3). L1 represents the least processed data products. Additional processing steps are required to transition the L1 data to the derived L2 and L3 data. Broadly, the L1 and L2 products are provided by individual aircraft flight line, while L3 products are provided in 1 km by 1 km tiles. Generally, the data volume for L1 products is the highest and decreases for L2 and L3 products. Details of the different products within each Level can be found in the individual webpages for each sensor. All AOP data products can be found on the NEON Data Portal, and a subset of the L3 data products are available on Google Earth Engine.\n\nImaging Spectrometer Data Products\nLevel 1 (L1) products include at-sensor radiance and surface reflectance which are distributed by flightline. The image data is georeferenced to the ITRF00 datum and projected into the appropriate UTM zone, and provided at 1 m spatial resolution. Both the radiance and reflectance image data are stored in an HDF5 file format that includes extensive metadata and data quality information. The HDF5 format was selected because of the flexibility it allows in storing associated metadata.\nLevel 2 (L2) products are derived from the L1 surface reflectance and are produced at the same spatial resolution (1 m), datum and map projection as the Level 1 products. The L2 products include a suite of spectral indices designed to strategically combine bands to highlight vegetation characteristics such as photosynthetic activity or water content. For example, NDVI (Normalized Difference Vegetation Index) is a well-known and commonly used vegetation index which combines information from the NIR and Red regions to estimate vegetative greenness and can be used as a proxy for plant health. The L2 products also include fPAR (fraction of photosynthetically active radiation) and LAI (leaf area index), products further derived from vegetation indices. Additionally, a surface Albedo product that estimates the integrated reflectance of all the NIS bands into a single value is also provided. All L2 products are distributed by flightline in a GeoTIFF (gtiff) format. Currently, all vegetation indices, water indices, fPAR, and LAI are delivered with associated simulated error images.\nLevel 3 (L3) products include mosaics of all L1 and L2 products, excluding at-sensor radiance, and are distributed as 1 km x 1 km tiles instead of flightlines. Tiles are created by making a full mosaic of all the data and sub-setting the 1 km x 1 km tiles. The tiles are designed so their boundaries are set to even 1000 m UTM coordinate intervals. During the mosaic generation, the algorithm preferentially selects pixels that were collected under the best weather conditions in regions with multiple potential pixels due to flightline overlap. If weather conditions were equivalent, pixels acquired nearest to nadir of the image acquisition are selected. Generally, this will correspond to pixels that are nearest to the center of the flightline. The tiles are created at the same spatial resolution (1 m) as the L1 and L2 products are in delivered in gtiff format, with the exception of the surface reflectance, which is delivered in HDF5 format.\n\nBRDF and topographic corrections\nStarting in 2024, NEON began producing BRDF (Bidirectional Reflectance Distribution Function) and topographic corrected reflectance data, which include “bidirectional” in the name, and end with revision .002 in the Data Product IDs. As of 2025, these bidirectional reflectance are currently only available for data collected between 2022-2024. NEON is beginning to back-process earlier years (pre-2022) to apply the BRDF and topographic corrections. Please look at the data availability charts for each product on the data portal to determine whether the bidirectional data are available. Eventually, only bidirectional data products will be delivered, with the exception of the Level 1 Spectrometer orthorectified surface directional reflectance (DP1.30006.001), which will continue to be delivered, so that researchers who wish to carry out their own BRDF, topographic, or other corrections may do so.\nTable 1 below shows a full list of NEON’s spectrometer-derived data products, including the corresponding bidirectional reflectance data products, if applicable.\n\n\n\nTable 1: NEON AOP Imaging Spectrometer Datasets\n\n\n\n\n\nProduct Name\nLevel\nData Product ID (DPID)\nBRDF-Corrected DPID\n\n\n\n\nSpectrometer orthorectified at-sensor radiance\nL1\nDP1.30008.001\n\n\n\nSpectrometer orthorectified surface (bi)directional reflectance\nL1\nDP1.30006.001\nDP1.30006.002\n\n\nAlbedo - spectrometer - flightline\nL2\nDP2.30011.001\nDP2.30011.002\n\n\nLAI - spectrometer - flightline\nL2\nDP2.30012.001\nDP2.30012.002\n\n\nfPAR - spectrometer - flightline\nL2\nDP2.30014.001\nDP2.30014.002\n\n\nCanopy water indices - flightline\nL2\nDP2.30019.001\nDP2.30019.002\n\n\nVegetation indices - spectrometer - flightline\nL2\nDP2.30026.001\nDP2.30026.002\n\n\nAlbedo - spectrometer - mosaic\nL3\nDP3.30011.001\nDP3.30011.002\n\n\nLAI - Spectrometer - mosaic\nL3\nDP3.30012.001\nDP3.30012.002\n\n\nfPAR - spectrometer - mosaic\nL3\nDP3.30014.001\nDP3.30014.002\n\n\nCanopy water indices - mosaic\nL3\nDP3.30019.001\nDP3.30019.002\n\n\nVegetation indices - spectrometer - mosaic\nL3\nDP3.30026.001\nDP3.30026.002\n\n\n\n\n\n\nIn addition to the spectrometer-derived data products, NEON generates 5 lidar-derived products (Table 2) and 2 RGB camera data products (Table 3), summarized below. These data products provide valuable structural and visual information that compliment the spectrometer data.\n\n\n\nLiDAR Data Products\n\n\n\nTable 2: NEON AOP Lidar Datasets\n\n\n\n\n\nProduct Name\nLevel\nData Product ID (DPID)\nATBD Document #\n\n\n\n\nLiDAR Slant Range Waveform\nL1\nDP1.30001.001\nNEON.DOC.001293\n\n\nDiscrete Return LiDAR Point Cloud\nL1\nDP1.30003.001\nNEON.DOC.001292, NEON.DOC.001288\n\n\nEcosystem Structure\nL3\nDP3.30015.001\nNEON.DOC.002387\n\n\nElevation – LiDAR\nL3\nDP3.30024.001\nNEON.DOC.002390\n\n\nSlope and Aspect – LiDAR\nL3\nDP3.30025.001\nNEON.DOC.003791\n\n\n\n\n\n\n\n\nRGB Camera Products\n\n\n\nTable 3: NEON AOP Camera Datasets\n\n\n\n\n\nProduct Name\nLevel\nData Product ID (DPID)\nATBD Document #\n\n\n\n\nHigh-resolution orthorectified camera imagery\nL1\nDP1.30010.001\nNEON.DOC.001211vB\n\n\nHigh-resolution orthorectified camera imagery mosaic\nL3\nDP3.30010.001\nNEON.DOC.005052vB",
    "crumbs": [
      "Background",
      "NEON Airborne Data Background"
    ]
  },
  {
    "objectID": "background/neon_background.html#neon-field-data",
    "href": "background/neon_background.html#neon-field-data",
    "title": "NEON Airborne and Field Datasets",
    "section": "NEON Field Data",
    "text": "NEON Field Data\nIn addition to the AOP remote sensing data, NEON also provides Observational Sampling (OS) data and Instrumented Sampling (IS) data at terrestrial and aquatic sites. The field and instrumented sampling are briefly described below, but we encourage exploring the NEON website further for a more detailed understanding of the sensors and data products provided by the OS and IS groups.\n\nObservational Sampling\n\n\n\nNEON Observational Samples\n\n\nNEON field scientists collect a broad variety of observations and samples at terrestrial and aquatic field sites at regular intervals throughout the year. The data and samples collected by NEON’s Aquatic Observation System (AOS) and Terrestrial Observation System (TOS) are designed to provide standardized, continentally distributed observations of organisms, biogeochemistry, and physical properties.\n\n\nInstrumented Sampling\n\n\n\nNEON Instrumented Sampling\n\n\nNEON deploys automated instruments to collect meteorological, soil, phenological, surface water, and groundwater data at NEON field sites.\nWhere logistically possible, NEON colocated aquatic sites with terrestrial sites (21 in total) to support an understanding of linkages across atmospheric, terrestrial, and aquatic ecosystems. The suite of OS, IS, and AOP data provide an unparalleled opportunity to study ecosystem-level change over time in the United States.",
    "crumbs": [
      "Background",
      "NEON Airborne Data Background"
    ]
  },
  {
    "objectID": "background/nasa_airborne_background.html",
    "href": "background/nasa_airborne_background.html",
    "title": "NASA Airborne and Field Datasets",
    "section": "",
    "text": "NASA has operated several airborne remote sensing platforms, including AVIRIS, HyTES (Hyperspectral Thermal Emissions Spectrometer), and MASTER (MODIS/ASTER Airborne Simulator). This workshop focuses on data from the AVIRIS sensors, which are the same family the NEON Imaging Spectrometers (AVIRIS-NG).",
    "crumbs": [
      "Background",
      "NASA Airborne Data Background"
    ]
  },
  {
    "objectID": "background/nasa_airborne_background.html#aviris-c-datasets",
    "href": "background/nasa_airborne_background.html#aviris-c-datasets",
    "title": "NASA Airborne and Field Datasets",
    "section": "AVIRIS-C Datasets",
    "text": "AVIRIS-C Datasets\nThe AVIRIS-C is an imaging spectrometer that delivers calibrated images of the upwelling spectral radiance in 224 contiguous spectral channels with wavelengths from 400 to 2500 nanometers (nm).\n\n\n\nData Product\n\n\n\n\nL1B Calibrated Radiance, Facility Instrument Collection\n\n\nL2 Calibrated Reflectance, Facility Instrument Collection",
    "crumbs": [
      "Background",
      "NASA Airborne Data Background"
    ]
  },
  {
    "objectID": "background/nasa_airborne_background.html#aviris-ng-datasets",
    "href": "background/nasa_airborne_background.html#aviris-ng-datasets",
    "title": "NASA Airborne and Field Datasets",
    "section": "AVIRIS-NG Datasets",
    "text": "AVIRIS-NG Datasets\nThe AVIRIS-NG is the successor to AVIRIS-Classic and provides high signal-to-noise ratio imaging spectroscopy measurements in 425 contiguous spectral channels with wavelengths in the solar reflected spectral range (380-2510 nm) with 5 nm sampling. The AVIRIS-NG started operation in 2014 and is expected to replace the AVIRIS-C instrument.\n\n\n\nData Product\n\n\n\n\nL1B Calibrated Radiance, Facility Instrument Collection\n\n\nL2 Surface Reflectance, Facility Instrument Collection",
    "crumbs": [
      "Background",
      "NASA Airborne Data Background"
    ]
  },
  {
    "objectID": "background/nasa_airborne_background.html#aviris-3-datasets",
    "href": "background/nasa_airborne_background.html#aviris-3-datasets",
    "title": "NASA Airborne and Field Datasets",
    "section": "AVIRIS-3 Datasets",
    "text": "AVIRIS-3 Datasets\nThe AVIRIS-3 is the third of the AVIRIS spectrometer FI series and has higher signal-to-noise ratio performance than AVIRIS-C or AVIRIS-NG. The core spectrometer of AVIRIS-3 is an optically fast, F/1.8 Dyson imaging spectrometer spanning a wide width (39.5-degree field of view). The AVIRIS-3 provides measurements in 285 contiguous spectral channels with wavelengths in the solar reflected spectral range (390-2500 nm) with 7.4 nm sampling. The AVIRIS-3 started operation in 2023.\n\n\n\nData Product\n\n\n\n\nL1B Calibrated Radiance, Facility Instrument Collection\n\n\nL2A Orthocorrected Surface Reflectance, Facility Instrument Collection\n\n\nL2B Greenhouse Gas Enhancements, Facility Instrument Collection",
    "crumbs": [
      "Background",
      "NASA Airborne Data Background"
    ]
  },
  {
    "objectID": "background/nasa_airborne_background.html#aviris-data-tutorials",
    "href": "background/nasa_airborne_background.html#aviris-data-tutorials",
    "title": "NASA Airborne and Field Datasets",
    "section": "AVIRIS Data Tutorials",
    "text": "AVIRIS Data Tutorials\n\nAVIRIS Data - Discovery, Access and Analysis",
    "crumbs": [
      "Background",
      "NASA Airborne Data Background"
    ]
  },
  {
    "objectID": "background/nasa_neon_comparison.html",
    "href": "background/nasa_neon_comparison.html",
    "title": "Comparing NEON and NASA Airborne Campaigns and Datasets",
    "section": "",
    "text": "While NASA and NEON operate similar imaging spectrometer instruments, there are a number of differences between the two in terms of the goals driving the airborne campaigns as well as the datasets provided. This section provides a high-level overview of some of the similarities and differences between the two. Table 1 shows some of the differences in terms of the major questions (when, where, why) about the two missions. Table 2 compares some of the differences in terms of the data products, processing methods, and data management (storage and access).\nWhile both NEON and NASA provide free, open datasets, the major difference between the NEON and NASA remote sensing airborne campaigns is related to their missions. NEON’s overarching mission is to produce a long-term archive of standardized data over the same sites over a 30 year time period, in order to provide a picture of long-term ecological change. NASA’s missions are campaign-driven, meaning that each campaign is typically designed around a specific research question, or instrument testing in some cases. For a more complete list of the NASA airborne campaigns hosted by the ORNL DAAC, refer to Datasets from Airborne Campaigns. Despite the differences in the drivers of the missions, the NEON and NASA datasets provide complimentary hyperspectral data, which could be used together for studies in their own right. In addition, both field and airborne datasets provide ground-truth (or close to ground-truth) sources that can help calibrate and validate data acquired from NASA’s upcoming Surface Biology and Geology SBG satellite mission.",
    "crumbs": [
      "Background",
      "Comparing NEON and NASA Airborne Campaigns"
    ]
  },
  {
    "objectID": "background/nasa_neon_comparison.html#data-products",
    "href": "background/nasa_neon_comparison.html#data-products",
    "title": "Comparing NEON and NASA Airborne Campaigns and Datasets",
    "section": "Data Products",
    "text": "Data Products\nNEON data are processed to Level 1 (flightline), Level 2 (derived; flightline) and Level 3 (derived; tiled mosaic) data products, and include a number of derived data products such as vegetation and water indices, LAI, fPAR, and Albedo. NASA data are processed to Level 1 (flightline) radiance, however some missions (e.g. BioSCape) have been mosaicked and tiled.",
    "crumbs": [
      "Background",
      "Comparing NEON and NASA Airborne Campaigns"
    ]
  },
  {
    "objectID": "background/nasa_neon_comparison.html#data-processing",
    "href": "background/nasa_neon_comparison.html#data-processing",
    "title": "Comparing NEON and NASA Airborne Campaigns and Datasets",
    "section": "Data Processing",
    "text": "Data Processing\n\nAtmospheric correction\nNEON uses ATCOR-4 for the atmospheric correction. NASA uses ISOFIT. There may be differences data derived from NEON v. NASA due to the different atmospheric correction method applied, as well as other corrections. NEON and NASA have been in communication about using the same atmospheric correction algorithm (ISOFIT) but this is still being scoped out.",
    "crumbs": [
      "Background",
      "Comparing NEON and NASA Airborne Campaigns"
    ]
  },
  {
    "objectID": "background/nasa_neon_comparison.html#data-storage-and-access",
    "href": "background/nasa_neon_comparison.html#data-storage-and-access",
    "title": "Comparing NEON and NASA Airborne Campaigns and Datasets",
    "section": "Data Storage and Access",
    "text": "Data Storage and Access\n\nNEON\nNEON data are stored on Google Cloud Storage (GCS) and are accessible via the NEON Data Portal. A subset of the L3 data products are also available on Google Earth Engine.\nNEON provides an API for downloading from the Data Portal, and has developed tools in R (neonUtilities) and Python (neonutilities) for downloading NEON data, and wrangling OS and IS data.\n\n\nNASA\nNASA airborne data are stored on Amazon Web Services (AWS) and can be accessed through the ORNL DAAC. NASA provides tools including Earthdata Search as well as the Python earthaccess package to help data users discover and download datasets.",
    "crumbs": [
      "Background",
      "Comparing NEON and NASA Airborne Campaigns"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "NEON’s Code of Conduct",
    "section": "",
    "text": "We are dedicated to fostering a respectful environment for everyone contributing to this project. We expect all participants to treat each other with respect, professionalism, and kindness.\n\n\n\n\nBe respectful and considerate of others.\nEngage in constructive discussions and offer helpful feedback.\nGracefully accept constructive criticism.\n\n\n\n\nThe following behaviors will not be tolerated:\n\nHarassment, discrimination, or intimidation of any kind.\nOffensive, abusive, or derogatory language and actions.\nPersonal attacks or insults.\nTrolling or disruptive conduct.\nSharing inappropriate content.\n\n\n\n\nIf you experience or witness any behavior that violates this Code of Conduct, please report it by contacting the project maintainers. All reports will be reviewed confidentially.\n\n\n\nViolations of this Code of Conduct may result in actions such as warnings, temporary bans, or permanent exclusion from participation at the discretion of the maintainers.",
    "crumbs": [
      "Code of Conduct",
      "NEON's Code of Conduct"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-commitment",
    "href": "CODE_OF_CONDUCT.html#our-commitment",
    "title": "NEON’s Code of Conduct",
    "section": "",
    "text": "We are dedicated to fostering a respectful environment for everyone contributing to this project. We expect all participants to treat each other with respect, professionalism, and kindness.",
    "crumbs": [
      "Code of Conduct",
      "NEON's Code of Conduct"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#expected-behavior",
    "href": "CODE_OF_CONDUCT.html#expected-behavior",
    "title": "NEON’s Code of Conduct",
    "section": "",
    "text": "Be respectful and considerate of others.\nEngage in constructive discussions and offer helpful feedback.\nGracefully accept constructive criticism.",
    "crumbs": [
      "Code of Conduct",
      "NEON's Code of Conduct"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#unacceptable-behavior",
    "href": "CODE_OF_CONDUCT.html#unacceptable-behavior",
    "title": "NEON’s Code of Conduct",
    "section": "",
    "text": "The following behaviors will not be tolerated:\n\nHarassment, discrimination, or intimidation of any kind.\nOffensive, abusive, or derogatory language and actions.\nPersonal attacks or insults.\nTrolling or disruptive conduct.\nSharing inappropriate content.",
    "crumbs": [
      "Code of Conduct",
      "NEON's Code of Conduct"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#reporting-violations",
    "href": "CODE_OF_CONDUCT.html#reporting-violations",
    "title": "NEON’s Code of Conduct",
    "section": "",
    "text": "If you experience or witness any behavior that violates this Code of Conduct, please report it by contacting the project maintainers. All reports will be reviewed confidentially.",
    "crumbs": [
      "Code of Conduct",
      "NEON's Code of Conduct"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "NEON’s Code of Conduct",
    "section": "",
    "text": "Violations of this Code of Conduct may result in actions such as warnings, temporary bans, or permanent exclusion from participation at the discretion of the maintainers.",
    "crumbs": [
      "Code of Conduct",
      "NEON's Code of Conduct"
    ]
  },
  {
    "objectID": "instructor-bios.html",
    "href": "instructor-bios.html",
    "title": "Workshop Instructors",
    "section": "",
    "text": "Bridget is a Data Scientist at NEON and splits her time between the Airborne Observation Platform (AOP) and Data Skills teams. She enjoys working on all things related to remote sensing data - including generating the data products, field work, calibration/validation, data management and teaching. Prior to working in remote sensing, she received her M.S. from Oregon State University specializing in marine geophysics, and worked at the Scripps Institution of Oceanography, supporting marine geophysical expeditions.",
    "crumbs": [
      "Welcome",
      "Instructors"
    ]
  },
  {
    "objectID": "instructor-bios.html#bridget-hass-neon",
    "href": "instructor-bios.html#bridget-hass-neon",
    "title": "Workshop Instructors",
    "section": "",
    "text": "Bridget is a Data Scientist at NEON and splits her time between the Airborne Observation Platform (AOP) and Data Skills teams. She enjoys working on all things related to remote sensing data - including generating the data products, field work, calibration/validation, data management and teaching. Prior to working in remote sensing, she received her M.S. from Oregon State University specializing in marine geophysics, and worked at the Scripps Institution of Oceanography, supporting marine geophysical expeditions.",
    "crumbs": [
      "Welcome",
      "Instructors"
    ]
  },
  {
    "objectID": "instructor-bios.html#michele-thornton-ornl-daac",
    "href": "instructor-bios.html#michele-thornton-ornl-daac",
    "title": "Workshop Instructors",
    "section": "Michele Thornton (ORNL DAAC)",
    "text": "Michele Thornton (ORNL DAAC)\nMichele is an ecologist and geospatial professional working at the Oak Ridge National Laboratory Distributed Active Archive Center (ORNL DAAC); part of NASA’s Earth Observing System Data and Information System and the ORNL Biological and Environmental Systems Science Directorate. Michele has served as the Project Lead for the production and tool development and distribution of the Daymet dataset since 2009. She also provides geospatial technical and scientific support for datasets curated and distributed within the ORNL DAAC. Michele enjoys working with the NASA and ORNL Science Community to both provide data that are useful in their applications and to help with the long term curation of terrestrial ecology datasets.",
    "crumbs": [
      "Welcome",
      "Instructors"
    ]
  },
  {
    "objectID": "instructor-bios.html#rupesh-shrestha-ornl-daac",
    "href": "instructor-bios.html#rupesh-shrestha-ornl-daac",
    "title": "Workshop Instructors",
    "section": "Rupesh Shrestha (ORNL DAAC)",
    "text": "Rupesh Shrestha (ORNL DAAC)\nRupesh is a research scientist at the ORNL DAAC. Rupesh has an extensive background in remote sensing applied to vegetation measurements, cyber-infrastructure development, and data science. Rupesh has led the development of several tools, algorithms, and data services that enable the estimation of earth science observables from satellite, airborne, and ground-based remote sensing. Rupesh holds a Ph.D. from Virginia Tech and M.S. in Photogrammetry and Geoinformatics from Stuttgart, Germany. He also serves as an adjunct faculty in the Department of Forestry, Wildlife & Fisheries at the University of Tennessee, Knoxville.",
    "crumbs": [
      "Welcome",
      "Instructors"
    ]
  },
  {
    "objectID": "neon/02_neon-refl-classification.html",
    "href": "neon/02_neon-refl-classification.html",
    "title": "Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray",
    "section": "",
    "text": "The National Ecological Observatory Network (NEON) Airborne Observation Platform (AOP) collects airborne remote sensing data, including hyperspectral reflectance data, over 81 sites across the United States and Puerto Rico. In this notebook we will show how to download and visualize reflectance data from NEON’s Smithsonian Environmental Research Center site (SERC) in Maryland. We will then demonstrate how to run a supervised classification using the NEON Observational System (OS) Vegetation Structure data as training data, and evaluate the model results.\n\n\n\nThe NEON Imaging Spectrometer (NIS) is an airborne imaging spectrometer built by JPL (AVIRIS-NG) and operated by the National Ecological Observatory Network’s (NEON) Airborne Observation Platform (AOP). NEON’s hyperspectral sensors collect measurements of sunlight reflected from the Earth’s surface in 426 narrow (~5 nm) spectral channels spanning wavelengths between ~ 380 - 2500 nm. NEON’s remote sensing data is intended to map and answer questions about a landscape, with ecological applications including identifying and classifying plant species and communities, mapping vegetation health, detecting disease or invasive species, and mapping droughts, wildfires, or other natural disturbances and their impacts.\nIn 2024, NEON started producing bidirectional reflectance data products (including BRDF and topographic corrections). These are currently available for AOP data collected between 2022-2025. For more details on this newly revised data product, please refer to the tutorial: Introduction to Bidirectional Hyperspectral Reflectance Data in Python.\nNEON surveys sites spanning the continental US, during peak phenological greenness, capturing each site 3 out of every 5 years, for most terrestrial sites. AOP’s Flight Schedules and Coverage provide’s more information about the current and past schedules.\nMore detailed information about NEON’s airborne sampling design can be found in the paper: Spanning scales: The airborne spatial and temporal sampling design of the National Ecological Observatory Network.\n\n\n\n\nNo Python setup requirements if connected to the workshop Openscapes cloud instance!\nLocal Only\n\nUsing your preferred command line interface (command prompt, terminal, etc.) navigate to your local copy of the repository, then type the following to create a compatible Python environment.\nFor Windows:\n\n```cmd\nconda create -n neon_aop -c conda-forge --yes python=3.10 fiona=1.8.22 gdal hvplot geoviews rioxarray rasterio geopandas jupyter jupyter_bokeh jupyterlab h5py spectral scikit-image scikit-learn seaborn neonutilities\n```\n\nFor MacOSX:\n\n```cmd\nconda create -n neon_aop -c conda-forge --yes python=3.10 gdal=3.7.2 hvplot geoviews rioxarray rasterio geopandas fiona=1.9.4 jupyter jupyter_bokeh jupyterlab h5py spectral scikit-image scikit-learn seaborn neonutilities\n```\n\n\n\n\nNEON API Token (optional, but strongly recommended), see NEON API Tokens Tutorial for more details on how to create and set up your token in Python (and R). Once you create your token (on the NEON User Accounts) page, this notebook will show you how to set it as an environment variable and use it for downloading AOP data.\n\n\n\n\nThe lesson shows how to programmatically download the NEON shapefiles, but you can also download them by clicking on the following links:\n\nAOP Flight Box Boundaries: AOP_FlightBoxes.zip\nTOS Sampling Boundaries: TOS_SamplingBoundaries.zip\n\n\n\n\n\nExplore NEON airborne and field (instrumented, observational) shapefiles to understand what colloated data are available\nUse the neonutilities package to determine available reflectance data and download\nUse a custom function to convert reflectance data into an xarray dataset\nCreate some interactive visualizations of reflectance data\nRun a random forest model to classify trees using reflectance data and data generated from vegetation structure (as the training data set)\nEvaluate classification model results\nUnderstand data QA considerations and potential steps to improve classification results\n\n\n\n\n\nSetup\nVisualize NEON AOP, OS, and IS shapefiles at SERC\nFind available NEON reflectance data at SERC and download\nRead in and visualize reflectance data interactively\nCreate a random forest model to predict the tree families from the reflectance spectra",
    "crumbs": [
      "Tutorials",
      "2 NEON - Reflectance Visualization and Classification"
    ]
  },
  {
    "objectID": "neon/02_neon-refl-classification.html#setup",
    "href": "neon/02_neon-refl-classification.html#setup",
    "title": "Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray",
    "section": "1. Setup",
    "text": "1. Setup\n\n1.1 Import Python Packages\nIf not already installed, install the neonutilities and python-dotenv packages using pip as follows: - !pip install neonutilities - !pip install python-dotenv\n\n# Import required libraries, grouped by functionality\n# --- System and utility packages ---\nfrom datetime import timedelta\nimport dotenv\nimport os\nimport requests\nfrom zipfile import ZipFile\n\n# --- Data handling and scientific computing ---\nimport math\nimport numpy as np\nimport pandas as pd\n\n# --- Geospatial and multi-dimensional raster data ---\nimport geopandas as gpd\nimport h5py\nimport rasterio as rio  # work with geospatial raster data\nimport rioxarray as rxr  # work with raster arrays\nfrom shapely import geometry\nfrom shapely.geometry.polygon import orient\nfrom osgeo import gdal  # work with raster and vector geospatial data\nimport xarray as xr\n\n# --- Plotting and visualization ---\nimport holoviews as hv\nimport hvplot.xarray  # plot multi-dimensional arrays\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport folium\n\n# --- neonutilities ---\nimport neonutilities as nu\n\n\n\n1.2 Set your NEON Token\nDefine your token. You can set this up on your NEON user account page, https://data.neonscience.org/myaccount. Please refer to the NEON API Tokens Tutorial for more details on how to create and set up your token in Python (and R).\n\n# method 1: set the NEON_TOKEN directly in your code\nNEON_TOKEN='YOUR_TOKEN_HERE'\n\n# method 2: set the token as an environment variable using the dotenv package\ndotenv.set_key(dotenv_path=\".env\",\nkey_to_set=\"NEON_TOKEN\",#\nvalue_to_set=\"YOUR_TOKEN_HERE\")\n\n# to retrieve the token that you set as an environment variable, use:\nNEON_TOKEN=os.environ.get(\"NEON_TOKEN\")",
    "crumbs": [
      "Tutorials",
      "2 NEON - Reflectance Visualization and Classification"
    ]
  },
  {
    "objectID": "neon/02_neon-refl-classification.html#visualize-neon-aop-os-and-is-shapefiles-at-serc",
    "href": "neon/02_neon-refl-classification.html#visualize-neon-aop-os-and-is-shapefiles-at-serc",
    "title": "Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray",
    "section": "2. Visualize NEON AOP, OS, and IS shapefiles at SERC",
    "text": "2. Visualize NEON AOP, OS, and IS shapefiles at SERC\nIn this next section, we will look at some of the NEON spatial data, honing in on our site of interest (SERC). We will look at the AOP flight box (the area over which the NEON AOP platform flies, including multiple priority boxes), the IS tower airshed, and the OS terrestrial sampling boundaries. This will provide an overview of how the NEON sites are set up, and the spatial overlap between the field and airborne data.\nFirst, let’s define a function that will download data from a url. We will use this to download shapefile boundares of the NEON AOP flight boxes, as well as the IS and OS shapefiles in order to see the spatial extent of the various data samples that NEON collects.\n\n# function to download data stored on the internet in a public url to a local file\ndef download_url(url,download_dir):\n    if not os.path.isdir(download_dir):\n        os.makedirs(download_dir)\n    filename = url.split('/')[-1]\n    r = requests.get(url, allow_redirects=True)\n    file_object = open(os.path.join(download_dir,filename),'wb')\n    file_object.write(r.content)\n\n\n2.1 NEON AOP flight box boundary\nDownload, Unzip, and Open the shapefile (.shp) containing the AOP flight box boundaries, which can also be downloaded from NEON Spatial Data and Maps. Read this shapefile into a geodataframe, explore the contents, and check the coordinate reference system (CRS) of the data.\n\n# Download and Unzip the NEON Flight Boundary Shapefile\naop_flight_boundary_url = \"https://www.neonscience.org/sites/default/files/AOP_flightBoxes_0.zip\"\n# Use download_url function to save the file to a directory\nos.makedirs('./data/shapefiles', exist_ok=True)\ndownload_url(aop_flight_boundary_url,'./data/shapefiles')\n# Unzip the file\nwith ZipFile(f\"./data/shapefiles/{aop_flight_boundary_url.split('/')[-1]}\", 'r') as zip_ref:\n    zip_ref.extractall('./data/shapefiles')\n\n\naop_flightboxes = gpd.read_file(\"./data/shapefiles/AOP_flightBoxes/AOP_flightboxesAllSites.shp\")\naop_flightboxes.head()\n\nNext, let’s examine the AOP flightboxes polygons at the SERC site.\n\nsite_id = 'SERC'\naop_flightboxes[aop_flightboxes.siteID == site_id]\n\nWe can see the site geodataframe consists of a single polygon, that we want to include in our study site (sometimes NEON sites may have more than one polygon, as there are sometimes multiple areas, with different priorities for collection).\n\n# write this to a new variable called \"site_polygon\"\nsite_aop_polygon = aop_flightboxes[aop_flightboxes.siteID == site_id]\n# subset to only include columns of interest\nsite_aop_polygon = site_aop_polygon[['domain','siteName','siteID','sampleType','flightbxID','priority','geometry']]\n# rename the flightbxID column to flightboxID for clarity\nsite_aop_polygon = site_aop_polygon.rename(columns={'flightbxID':'flightboxID'})\nsite_aop_polygon # display site polygon\n\nNext we can visualize our region of interest (ROI) and the exterior boundary polygon containing ROIs.\nNow let’s define a function that uses folium to display the bounding box polygon on a map. We will first use this function to visualize the AOP flight box polygon, and then we will use it to visualize the IS and OS polygons as well.\n\ndef plot_folium_shapes(\n    shapefiles,      # list of file paths or GeoDataFrames\n    styles=None,     # list of style dicts for each shapefile\n    names=None,      # list of names for each shapefile\n    map_center=None, # [lat, lon]\n    zoom_start=12\n):\n    import pyproj\n    # If no center is provided, use the centroid of the first shapefile (projected)\n    if map_center is None:\n        if isinstance(shapefiles[0], str):\n            gdf = gpd.read_file(shapefiles[0])\n        else:\n            gdf = shapefiles[0]\n        # Project to Web Mercator (EPSG:3857) for centroid calculation\n        gdf_proj = gdf.to_crs(epsg=3857)\n        centroid = gdf_proj.geometry.centroid.iloc[0]\n        # Convert centroid back to lat/lon\n        lon, lat = gpd.GeoSeries([centroid], crs=\"EPSG:3857\").to_crs(epsg=4326).geometry.iloc[0].coords[0]\n        map_center = [lat, lon]\n    \n    m = folium.Map(\n        location=map_center,\n        zoom_start=zoom_start,\n        tiles=None\n    )\n    folium.TileLayer(\n        tiles='https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',\n        attr='Google',\n        name='Google Satellite'\n    ).add_to(m)\n    \n    for i, shp in enumerate(shapefiles):\n        if isinstance(shp, str):\n            gdf = gpd.read_file(shp)\n        else:\n            gdf = shp\n        style = styles[i] if styles and i &lt; len(styles) else {}\n        layer_name = names[i] if names and i &lt; len(names) else f\"Shape {i+1}\"\n        folium.GeoJson(\n            gdf,\n            name=layer_name,\n            style_function=lambda x, style=style: style,\n            tooltip=layer_name\n        ).add_to(m)\n    \n    folium.LayerControl().add_to(m)\n    return m\n\n\nmap1 = plot_folium_shapes(\n    shapefiles=[site_aop_polygon],\n    names=['NEON AOP Flight Bounding Box']\n)\n\nmap1\n\n\n \n\nAOP flight box polygon at the SERC site.\n\n\n\n\n\n2.2 NEON OS terrestrial sampling boundaries\nWe will follow a similar process to download and visualize the NEON OS terrestrial sampling boundaries. The OS terrestrial sampling boundaries are also available as a shapefile, which can be downloaded from NEON Spatial Data and Maps page.\n\n# Download and Unzip the NEON Terrestrial Field Sampling Boundaries Shapefile\nneon_field_boundary_file = \"https://www.neonscience.org/sites/default/files/Field_Sampling_Boundaries_202503.zip\"\n# Use download_url function to save the file to the data directory\ndownload_url(neon_field_boundary_file,'./data/shapefiles')\n\n\n# Unzip the file\nwith ZipFile(f\"./data/shapefiles/Field_Sampling_Boundaries_202503.zip\", 'r') as zip_ref:\n    zip_ref.extractall('./data/shapefiles')\n\n\nneon_terr_bounds = gpd.read_file(\"./data/shapefiles/Field_Sampling_Boundaries/terrestrialSamplingBoundaries.shp\")\nneon_terr_bounds.head()\n\n\n# save the boundaries for the site to a new variable called \"site_terr_bounds\"\nsite_terr_bounds = neon_terr_bounds[neon_terr_bounds.siteID == site_id]\nsite_terr_bounds.head()\n\n\n\n2.3 NEON IS tower footprint boundaries\nLastly, we’ll download and read in the IS tower footprint shapefile, which represents the area of the airshed over which the IS tower collects data. This shapefile is available from the NEON Spatial Data and Maps page, but is pre-downloaded for convenience.\n\n# unzip the 90 percent footprint tower airshed file\nwith ZipFile(f\"./data/90percentfootprint.zip\", 'r') as zip_ref:\n    zip_ref.extractall('./data/shapefiles')\n\n\n# read in the neon tower airshed polygon shapefile and display\nneon_tower_airshed = gpd.read_file(\"./data/shapefiles/90percentfootprint/90percent_footprint.shp\")\nneon_tower_airshed.head()\n\n\n# save the boundaries for the site to a new variable called \"site_terr_bounds\"\nsite_tower_bounds = neon_tower_airshed[neon_tower_airshed.SiteID == site_id]\nsite_tower_bounds.head()\n\n\n\n2.4 Visualize AOP, OS, and IS boundaries together\nNow that we’ve read in all the shapefiles into geodataframes, we can visualize them all together as follows. We will use the plot_folium_shapes function defined above, and define a styles list of dictionaries specifying the color, so that we can display each polygon with a different color.\n\nneon_shapefiles = [site_aop_polygon, site_terr_bounds, site_tower_bounds]\n\n# define a list of styles for the polygons\n# each style is a dictionary with 'fillColor' and 'color' keys\nstyles = [\n    {'fillColor': '#228B22', 'color': '#228B22'}, # green\n    {'fillColor': '#00FFFFFF', 'color': '#00FFFFFF'}, # blue\n    {'fillColor': '#FF0000', 'color': '#FF0000'}, # red\n    {'fillColor': '#FFFF00', 'color': '#FFFF00'}, # yellow\n]\n\nmap2 = plot_folium_shapes(\n    shapefiles=neon_shapefiles,\n    names=['NEON AOP Flight Bounding Box', 'NEON Terrestrial Sampling Boundaries', 'NEON Tower Airshed'],\n    styles=styles\n)\n\nmap2\n\n\n \n\nAOP, OS, and IS polygons at the SERC site.\n\n\n\nAbove we can see the SOAP flightbox, and the exterior TOS boundary polygon which shows the extent of the area where observational data are collected.",
    "crumbs": [
      "Tutorials",
      "2 NEON - Reflectance Visualization and Classification"
    ]
  },
  {
    "objectID": "neon/02_neon-refl-classification.html#find-available-neon-reflectance-data-and-download",
    "href": "neon/02_neon-refl-classification.html#find-available-neon-reflectance-data-and-download",
    "title": "Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray",
    "section": "3. Find available NEON reflectance data and download",
    "text": "3. Find available NEON reflectance data and download\nFinally we can look at the available NEON hyperspectral reflectance data, which are delivered as 1 km by 1 km hdf5 files (also called tiles) over the site. The next figure we make will make it clear why the files are called tiles. First, we will determine the available reflectance data, and then pull in some metadata shapefiles from another L3 AOP data product, derived from the lidar data.\nNEON hyperspectral reflectance data are currently available under two different revisions, as AOP is in the process of implementing a BRDF (Bidirectional Reflectance Distribution Function), but this has not been applied to the full archive of data yet. These data product IDs are DP3.30006.001 (directional surface reflectance), and DP3.30006.002 (bidirectional surface reflectance). The bidirectional surface reflectance data include BRDF and topographic corrections, which helps correct for differences in illumination throughout the flight.\n\n3.1 Find available data\nLet’s see what data are available at the SERC site for each of these data products using the neonutilities list_available_dates function as follows:\n\n# define the data product IDs for the reflectance data\nrefl_rev1_dpid = 'DP3.30006.001'\nrefl_rev2_dpid = 'DP3.30006.002'\n\n\nprint(f'Directional Reflectance Data Available at NEON Site {site_id}:')\nnu.list_available_dates(refl_rev1_dpid,site_id)\n\n\nprint(f'Bidirectional Reflectance Data Available at NEON Site {site_id}:')\nnu.list_available_dates(refl_rev2_dpid,site_id)\n\nThe dates provided are the year and month that the data were published (YYYY-MM). A single site may be collected over more than one month, so this publish date typically represents the month where the majority of the flight lines were collected. There are released directional reflectance data available from 2016 to 2021, and provisional bidirectional reflectance data available in 2022 and 2025. As of 2025, bidirectional data are only available provisionally because they were processed in 2024 (there is a year lag-time before data is released to allow for time to review for data quality issues).\nFor this exercise, we’ll look at the most recent data, from 2025. You may wish to consider other factors, for example if you collected field data in a certain year, you are looking at a year when there was a recent disturbance, or if you want to find the clearest weather data (data are not always collected in optimal sky conditions). For SERC, the most recent clear (&lt;10% cloud cover) weather collection to date was in 2017, so this directional reflectance data may be another good option to consider for your analysis.\nFor this lesson, we will use the 2025 bidirectional reflectance data, which is provisional.\n\nyear = '2025'\n\n\n\n3.2 Download NEON Lidar data using neonutilities by_file_aop\nWe can download the reflectance data either using the neonutilities function nu.by_file_aop, which downloads all tiles for the entire site for a given year, or nu.by_tile_aop. To figure out the inputs of these functions, you can type nu.by_tile_aop?, for example.\nAOP data are projected into a WGS84 coordinate system, with coordinates in UTM x, y. When using nu.by_tile_aop you need to specify the UTM easting and northing values for the tiles you want to download. If you’re not sure the extent of the site, you can use the function nu.get_aop_tile_extents. Let’s do that here, for the SOAP site collected in 2024.You will use the same token you defined at the beginning of the tutorial\n\nserc2025_utm_extents = nu.get_aop_tile_extents(refl_rev2_dpid, \n                                               site_id,\n                                               year,\n                                               token=NEON_TOKEN)\n\nThe AOP collection over SERC in 2025 extends from UTM 358000 - 370000 m (Easting) and 4298000 - 4312000 m (Northing). To display a list of the extents of every tile, you can print serc2025_utm_extents. This is sometimes useful when trying to determine the extents of irregularly shaped sites.\nWe can also look at the full extents by downloading one of the smaller lidar raster data products to start. The L3 lidar data products include metadata shapefiles that can be useful for understanding the spatial extents of the individual files that comprise the data product. To show how to look at these shapefiles, we can download the Canopy Height Model data (DP3.30015.001). The next cell shows how to do this:\n\n# download all CHM tiles (https://data.neonscience.org/data-products/DP3.30015.001)\nnu.by_file_aop(dpid='DP3.30015.001', # Ecosystem Structure / CHM \n               site=site_id,\n               year=year,\n               include_provisional=True,\n               token=NEON_TOKEN,\n               savepath='./data')\n\nThe function below displays all of the folders that we’ve downloaded. You can also use your File Explorer to look at the contents of what you have downloaded.\n\ndef find_data_subfolders(root_dir):\n    \"\"\"\n    Recursively finds subfolders within a directory that contain data (files)\n    and excludes subfolders that only contain other subfolders.\n\n    Args:\n        root_dir: The path to the root directory to search.\n\n    Returns:\n        A list of paths to the subfolders containing data.\n    \"\"\"\n    data_subfolders = []\n    for root, dirs, files in os.walk(root_dir):\n        # Check if the current directory has both subdirectories and files\n        if dirs and files:\n            # Iterate through subdirectories to find those that contain files\n            for dir_name in dirs:\n                dir_path = os.path.join(root, dir_name)\n                if any(os.path.isfile(os.path.join(dir_path, f)) for f in os.listdir(dir_path)):\n                    data_subfolders.append(dir_path)\n        # If the current directory has no subdirectories, but has files, we still want to keep the directory.\n        elif files:\n            if root != root_dir:  # Avoid adding the root directory itself if it has files\n                data_subfolders.append(root)\n\n    return data_subfolders\n\n\n# use the find_data_subfolders function to see what has been downloaded\nchm_subfolders = find_data_subfolders(r'./data/DP3.30015.001')\nchm_subfolders # display the subfolders\n\n\n# see the path of the zip file that was downloaded (ends in .zip):\nfor root, dirs, files in os.walk(r'./data/DP3.30015.001'):\n    for name in files:\n        if name.endswith('.zip'):\n            print(os.path.join(root, name))  # print file name\n\n\n# unzip the lidar tile boundary file\n# uncomment if you skipped the download section, and comment the next line (starting with \"with ZipFile\")\n# with ZipFile(f\"./data/shapefiles/2025_SERC_7_TileBoundary.zip\", 'r') as zip_ref: \nwith ZipFile(f\"./data/DP3.30015.001/neon-aop-provisional-products/2025/FullSite/D02/2025_SERC_7/Metadata/DiscreteLidar/TileBoundary/2025_SERC_7_TileBoundary.zip\",'r') as zip_ref:\n    zip_ref.extractall('./data/shapefiles/2025_SERC_7_TileBoundary')\n\n\n# read in the tile bounadry shapefile\naop_tile_boundaries = gpd.read_file(\"./data/shapefiles/2025_SERC_7_TileBoundary/shps/NEON_D02_SERC_DPQA_2025_merged_tiles_boundary.shp\")\n\n\n# append this last boundary file to the existing neon_shapefiles list\nneon_shapefiles.append(aop_tile_boundaries)\n\n# plot all NEON SERC shapefiles together\nmap3 = plot_folium_shapes(\n    shapefiles=neon_shapefiles,\n    names=['NEON AOP Flight Bounding Box', 'NEON Terrestrial Sampling Boundaries', 'NEON Tower Airshed', 'AOP Tile Boundaries'],\n    styles=styles,\n    zoom_start=12\n)\n\nmap3\n\n\n \n\nAOP, OS, and IS polygons at the SERC site.\n\n\n\nFrom the image above, you can see why the data are called “tiles”! The individual tiles make up a grid comprising the full site. These smaller areas make it easier to process the large data, and allow for batch processing instead of running an operation on a huge file, which might cause memory errors.\n\n\n3.3 Download NEON Reflectance Data using neonutilities by_tile_aop\nNow that we’ve explored the spatial extent of the NEON airborne data, as well as the OS terrestrial sampling plots and the IS tower airshed, we can start playing with the data! First, let’s download a single tile to start. For this exercise we’ll download the tile that encompasses the NEON tower, since there is typically more OS sampling in the NEON tower plots. The tile of interest for us is 365000_4305000 (note that AOP tiles are named by the SW or lower-left coordinate of the tile).\nYou can specify the download path using the savepath variable. Let’s set it to a data directory in line with the root directory where we’re working, in this case we’ll set it to ./data/NEON/refl.\nThe reflectance data are large in size (especially for an entire site’s worth of data), so by default the download functions will display the expected download size and ask if you want to proceed with the download (y/n). The reflectance tile downloaded below is ~ 660 MB in size, so make sure you have enough space on your local disk (or cloud platform) before downloading. If you want to download without being prompted to continue, you can set the input variable check_size=False.\nBy default the files will be downloaded following the same structure that they are stored in on Google Cloud Storage, so the actual data files are nested in sub-folders. We encourage you to navigate through the data/DP3.30006.002 folder, and explore the additional metadata (such as QA reports) that are downloaded along with the data.\n\n# download the tile that encompasses the NEON tower\nnu.by_tile_aop(dpid='DP3.30006.002',\n               site=site_id,\n               year=2025,\n               easting=364005,\n               northing=4305005,\n               include_provisional=True,\n               token=NEON_TOKEN,\n               savepath='./data')\n\nYou can either navigate to the download folder in File Explorer, or to programmatically see what files were downloaded, you can display the files as follows:\n\n# see all files that were downloaded (including data, metadata, and READMEs):\nfor root, dirs, files in os.walk(r'./data/DP3.30006.002'):\n    for name in files:\n        print(os.path.join(root, name))  # print file name\n\nYou can see there are several .txt and .csv files in addition to the .h5 data file (NEON_D02_SERC_DP3_364000_4305000_bidirectional_reflectance.h5). These include citation information: citation_DP3.30006.002_PROVISIONAL.txt, an issue log: issueLog_DP3.30006.002.csv, and a README: NEON.D02.SERC.DP3.30006.002.readme.20250719T050120Z.txt. We encourage you to look through these files, particularly the issue log, which conveys information about issues and the resolution for the data product in question. Make sure there is not a known issue with the data you downloaded, especially since it is provisional.\nIf you only want to see the names of the .h5 reflectance data you downloaded, you can modify the code as follows:\n\n# see only the .h5 files that were downloaded\nfor root, dirs, files in os.walk(r'./data/DP3.30006.002'):\n    for name in files:\n        if name.endswith('.h5'):\n            print(os.path.join(root, name))  # print file name\n\nSuccess! We’ve now downloaded a NEON bidirectional surface reflectance tile into our data directory.",
    "crumbs": [
      "Tutorials",
      "2 NEON - Reflectance Visualization and Classification"
    ]
  },
  {
    "objectID": "neon/02_neon-refl-classification.html#read-in-and-visualize-reflectance-data-interactively",
    "href": "neon/02_neon-refl-classification.html#read-in-and-visualize-reflectance-data-interactively",
    "title": "Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray",
    "section": "4. Read in and visualize reflectance data interactively",
    "text": "4. Read in and visualize reflectance data interactively\n\n4.1 Convert Reflectance Data to an xarray Dataset\nThe function below will read in a NEON reflectance hdf5 dataset and export an xarray dataset. According to the xarray documentation, “xarray makes working with labelled multi-dimensional arrays in Python simple, efficient, and fun!” rioxarray is simply the rasterio xarray extension, so you can work with xarray for geospatial data.\n\ndef aop_h5refl2xarray(h5_filename):\n    \"\"\"\n    Reads a NEON AOP reflectance HDF5 file and returns an xarray.Dataset with reflectance and weather quality indicator data.\n\n    Parameters\n    ----------\n    h5_filename : str\n        Path to the NEON AOP reflectance HDF5 file.\n\n    Returns\n    -------\n    dsT : xarray.Dataset\n        An xarray Dataset containing:\n            - 'reflectance': DataArray of reflectance values (y, x, wavelengths)\n            - 'weather_quality_indicator': DataArray of weather quality indicator (y, x)\n            - Coordinates: y (UTM northing), x (UTM easting), wavelengths, fwhm, good_wavelengths\n            - Metadata attributes: projection, spatial_ref, EPSG, no_data_value, scale_factor, bad_band_window1, bad_band_window2, etc.\n    \"\"\"\n    import h5py\n    import numpy as np\n    import xarray as xr\n\n    with h5py.File(h5_filename) as hdf5_file:\n        print('Reading in ', h5_filename)\n        sitename = list(hdf5_file.keys())[0]\n        h5_refl_group = hdf5_file[sitename]['Reflectance']\n        refl_dataset = h5_refl_group['Reflectance_Data']\n        refl_array = refl_dataset[()].astype('float32')\n\n        # Transpose and flip reflectance data\n        refl_arrayT = np.transpose(refl_array, (1, 0, 2))\n        refl_arrayT = refl_array[::-1, :, :]\n\n        refl_shape = refl_arrayT.shape\n        wavelengths = h5_refl_group['Metadata']['Spectral_Data']['Wavelength'][:]\n        fwhm = h5_refl_group['Metadata']['Spectral_Data']['FWHM'][:]\n\n        # Weather Quality Indicator: transpose and flip to match reflectance\n        wqi_array = h5_refl_group['Metadata']['Ancillary_Imagery']['Weather_Quality_Indicator'][()]\n        wqi_arrayT = np.transpose(wqi_array, (1, 0))\n        wqi_arrayT = wqi_array[::-1, :]\n\n        # Collect metadata\n        metadata = {}\n        metadata['shape'] = refl_shape\n        metadata['no_data_value'] = float(refl_dataset.attrs['Data_Ignore_Value'])\n        metadata['scale_factor'] = float(refl_dataset.attrs['Scale_Factor'])\n        metadata['bad_band_window1'] = h5_refl_group.attrs['Band_Window_1_Nanometers']\n        metadata['bad_band_window2'] = h5_refl_group.attrs['Band_Window_2_Nanometers']\n        metadata['projection'] = h5_refl_group['Metadata']['Coordinate_System']['Proj4'][()].decode('utf-8')\n        metadata['spatial_ref'] = h5_refl_group['Metadata']['Coordinate_System']['Coordinate_System_String'][()].decode('utf-8')\n        metadata['EPSG'] = int(h5_refl_group['Metadata']['Coordinate_System']['EPSG Code'][()])\n\n        # Parse map info for georeferencing\n        map_info = str(h5_refl_group['Metadata']['Coordinate_System']['Map_Info'][()]).split(\",\")\n        pixel_width = float(map_info[5])\n        pixel_height = float(map_info[6])\n        x_min = float(map_info[3]); x_min = int(x_min)\n        y_max = float(map_info[4]); y_max = int(y_max)\n        x_max = x_min + (refl_shape[1]*pixel_width); x_max = int(x_max)\n        y_min = y_max - (refl_shape[0]*pixel_height); y_min = int(y_min)\n\n        # Calculate UTM coordinates for x and y axes\n        x_coords = np.linspace(x_min, x_max, num=refl_shape[1]).astype(float)\n        y_coordsT = np.linspace(y_min, y_max, num=refl_shape[0]).astype(float)\n\n        # Flag good/bad wavelengths (1=good, 0=bad)\n        good_wavelengths = np.ones_like(wavelengths)\n        for bad_window in [metadata['bad_band_window1'], metadata['bad_band_window2']]:\n            bad_indices = np.where((wavelengths &gt;= bad_window[0]) & (wavelengths &lt;= bad_window[1]))[0]\n            good_wavelengths[bad_indices] = 0\n        good_wavelengths[-10:] = 0\n\n        # Create xarray DataArray for reflectance\n        refl_xrT = xr.DataArray(\n            refl_arrayT,\n            dims=[\"y\", \"x\", \"wavelengths\"],\n            name=\"reflectance\",\n            coords={\n                \"y\": (\"y\", y_coordsT),\n                \"x\": (\"x\", x_coords),\n                \"wavelengths\": (\"wavelengths\", wavelengths),\n                \"fwhm\": (\"wavelengths\", fwhm),\n                \"good_wavelengths\": (\"wavelengths\", good_wavelengths)\n            }\n        )\n\n        # Create xarray DataArray for Weather Quality Indicator\n        wqi_xrT = xr.DataArray(\n            wqi_arrayT,\n            dims=[\"y\", \"x\"],\n            name=\"weather_quality_indicator\",\n            coords={\n                \"y\": (\"y\", y_coordsT),\n                \"x\": (\"x\", x_coords)\n            }\n        )\n\n        # Create xarray Dataset and add metadata as attributes\n        dsT = xr.Dataset({\n            \"reflectance\": refl_xrT,\n            \"weather_quality_indicator\": wqi_xrT\n        })\n        for key, value in metadata.items():\n            if key not in ['shape', 'extent', 'ext_dict']:\n                dsT.attrs[key] = value\n\n        return dsT\n\nNow that we’ve defined a function that reads in the reflectance hdf5 data and exports an xarray dataset, we can apply this function to our downloaded reflectance data. This should take around 15 seconds or so to run.\n\n%%time\n# uncomment the line below and comment the following one if running from the Openscapes platform and you skipped the download step\n# serc_refl_h5 = serc_refl_h5 = r'../../shared-public/data/neon/NEON_D02_SERC_DP3_364000_4305000_bidirectional_reflectance.h5'\nserc_refl_h5 = r'./data/DP3.30006.002/neon-aop-provisional-products/2025/FullSite/D02/2025_SERC_7/L3/Spectrometer/Reflectance/NEON_D02_SERC_DP3_364000_4305000_bidirectional_reflectance.h5'\nserc_refl_xr = aop_h5refl2xarray(serc_refl_h5)\n\nNext let’s define a function that updates the neon reflectance xarray dataset to apply the no data value (-9999), set the bad bands to NaN, and applies the CRS to make the xarray objet an rioxarray object. These could also be incorporated into the function above, but you may wish to work with unscaled reflectance data, for example, so we will keep these functions separate for now.\n\ndef update_neon_xr(neon_refl_ds):\n\n    # Set no data values (-9999) equal to np.nan\n    neon_refl_ds.reflectance.data[neon_refl_ds.reflectance.data == -9999] = np.nan\n    \n    # Scale by the reflectance scale factor\n    neon_refl_ds['reflectance'].data = ((neon_refl_ds['reflectance'].data) /\n                                        (neon_refl_ds.attrs['scale_factor']))\n    \n    # Set \"bad bands\" (water vapor absorption bands and noisy bands) to NaN\n    neon_refl_ds['reflectance'].data[:,:,neon_refl_ds['good_wavelengths'].data==0.0] = np.nan\n\n    neon_refl_ds.rio.write_crs(f\"epsg:{neon_refl_ds.attrs['EPSG']}\", inplace=True)\n    \n    return neon_refl_ds\n\nApply this function on our xarray dataset.\n\nserc_refl_xr = update_neon_xr(serc_refl_xr)\n\n\n\n4.2 Visualize the reflectance dataset\nDisplay the dataset. You can use the up and down arrows to the left of the table (e.g. to the left of Dimensions, Coordinates, Data variables, etc.) to explore each part of the dataset in more detail. You can also click on the icons to the right to see more details.\n\nserc_refl_xr\n\n\n# function to auto-scale to make RGB images more realistic\ndef gamma_adjust(rgb_ds, bright=0.2, white_background=False):\n    array = rgb_ds.reflectance.data\n    gamma = math.log(bright)/math.log(np.nanmean(array)) # Create exponent for gamma scaling - can be adjusted by changing 0.2 \n    scaled = np.power(np.nan_to_num(array,nan=1),np.nan_to_num(gamma,nan=1)).clip(0,1) # Apply scaling and clip to 0-1 range\n    if white_background == True:\n        scaled = np.nan_to_num(scaled, nan = 1) # Set NANs to 1 so they appear white in plots\n    rgb_ds.reflectance.data = scaled\n    return rgb_ds\n\n\n\n4.3 Plot the reflectance dataset\nNow let’s plot a true color (or RGB) image of the reflectance data as shown in the cell below.\n\n# Plot the RGB image of the SERC tower tile\nserc_refl_rgb = serc_refl_xr.sel(wavelengths=[650, 560, 470], method='nearest')\nserc_refl_rgb = gamma_adjust(serc_refl_rgb,bright=0.3,white_background=True)\n\nserc_rgb_plot = serc_refl_rgb.hvplot.rgb(y='y',x='x',bands='wavelengths',\n                         xlabel='UTM x',ylabel='UTM y',\n                         title='NEON AOP Reflectance RGB - SERC Tower Tile',\n                         frame_width=480, frame_height=480)\n\n# Set axis format to integer (no scientific notation)\nserc_rgb_plot = serc_rgb_plot.opts(\n    xformatter='%.0f',\n    yformatter='%.0f'\n)\n\nserc_rgb_plot\n\n\n\n4.4 Plot the weather quality indicator data\nWe can look at the weather conditions during the flight by displaying the weather_quality_indicator data array. This is a 2D array with values ranging from 1 to 3, where: 1 = &lt;10% cloud cover, 2 = 10-50% cloud cover, 3 = &gt;50% cloud cover. NEON uses a stop-light convention to indicate the weather and cloud conditions, where green (1) is good, yellow (2) is moderate, and red (3) is poor. The figure below shows some examples of these three conditions as captured by the flight operators during science flights.\n\n \n\nCloud cover percentage during AOP flights. Left: green (&lt;10%), Middle: yellow (10-50%), Right: red (&gt;50%).\n\n\n\nLet’s visualize this weather quality indicator data for this SERC tile using a transparent color on top of our RGB reflectance plot, following the same stop-light convention.\n\n# Prepare the WQI mask\nwqi = serc_refl_xr.weather_quality_indicator\n\n# Map WQI values to colors: 1=green, 2=yellow, 3=red, 0/other=transparent\nwqi_colors = ['#228B22', '#FFFF00', '#FF0000']\n# wqi_mask = wqi[wqi &gt; 0]  # mask out zeros or nodata\n\n# Use hvplot with categorical colormap and alpha (50% transparency)\nwqi_overlay = wqi.hvplot.image(\n    x='x', y='y', cmap=wqi_colors,\n    clim=(1, 3), colorbar=False, alpha=0.5, \n    xlabel='UTM x', ylabel='UTM y',\n    title='NEON AOP Reflectance Weather Quality - SERC Tower Tile',\n    frame_width=480, frame_height=480)\n\n# Overlay the RGB and WQI\n(serc_rgb_plot * wqi_overlay).opts(title=\"RGB + Weather Quality Indicator\").opts(xformatter='%.0f',\n                                                                                 yformatter='%.0f')\n\nThe cloud conditions for this tile are yellow, which indicates somewhere between 10-50% cloud cover, which is moderate. This is not ideal for reflectance data, but it is still usable. As we will use this data for classification, you would want to consider how the cloud cover may impact your results. You may wish to find a clear-weather (&lt;10% cloud cover) tile to run classification, or at a minimum compare results between the two to better understand how cloud cover impacts the model.\n\n\n4.5 Plot a false color image\nLet’s continue visualizing the data, next by making a False-Color image, which is a 3-band combination that shows you more than what you would see with the naked eye. For example, you can pull in SWIR or NIR bands to create an image that shows more information about vegetation health Here we will use a SWIR band (2000 nm), a NIR band (850 nm), and blue band (450 nm). Try some different band combinations on your own, remembering not to use bands that are flagged as bad (e.g. the last 10 bands, or those in the bad band windows between 1340-1445 nm and between 1790-1955 nm).\n\n# Plot a False-Color image of the SERC tower tile\nserc_refl_false_color = serc_refl_xr.sel(wavelengths=[2000, 850, 450], method='nearest')\nserc_refl_false_color = gamma_adjust(serc_refl_false_color,bright=0.3,white_background=True)\nserc_refl_false_color.hvplot.rgb(y='y',x='x',bands='wavelengths',\n                         xlabel='UTM x',ylabel='UTM y',\n                         title='NEON AOP Reflectance False Color Image - SERC Tower Tile',\n                         frame_width=480, frame_height=480).opts(xformatter='%.0f', yformatter='%.0f')\n\n\n\n4.6 Make an interactive spectral signature plot\nWe can also make an interactive plot that displays the spectral signature of the reflectance data for any pixel you click on. This is useful for exploring the spectral signature of different land cover types, and can help you identify which bands may be most useful for classification.\n\n# Interactive Points Plotting\n# Modified from https://github.com/auspatious/hyperspectral-notebooks/blob/main/03_EMIT_Interactive_Points.ipynb\nPOINT_LIMIT = 10\ncolor_cycle = hv.Cycle('Category20')\n\n# Create RGB Map\nmap = serc_refl_rgb.hvplot.rgb(x='x', y='y',\n                               bands='wavelengths',\n                               fontscale=1.5,\n                               xlabel='UTM x', ylabel='UTM y',\n                               frame_width=480, frame_height=480).opts(xformatter='%.0f', yformatter='%.0f')\n\n# Set up a holoviews points array to enable plotting of the clicked points\nxmid = serc_refl_rgb.x.values[int(len(serc_refl_rgb.x) / 2)]\nymid = serc_refl_rgb.y.values[int(len(serc_refl_rgb.y) / 2)]\n\nx0 = serc_refl_rgb.x.values[0]\ny0 = serc_refl_rgb.y.values[0]\n\n# first_point = ([xmid], [ymid], [0])\nfirst_point = ([x0], [y0], [0])\npoints = hv.Points(first_point, vdims='id')\npoints_stream = hv.streams.PointDraw(\n    data=points.columns(),\n    source=points,\n    drag=True,\n    num_objects=POINT_LIMIT,\n    styles={'fill_color': color_cycle.values[1:POINT_LIMIT+1], 'line_color': 'gray'}\n)\n\nposxy = hv.streams.PointerXY(source=map, x=xmid, y=ymid)\nclickxy = hv.streams.Tap(source=map, x=xmid, y=ymid)\n\n# Function to build spectral plot of clicked location to show on hover stream plot\ndef click_spectra(data):\n    coordinates = []\n    if data is None or not any(len(d) for d in data.values()):\n        coordinates.append(clicked_points[0][0], clicked_points[1][0])\n    else:\n        coordinates = [c for c in zip(data['x'], data['y'])]\n    \n    plots = []\n    for i, coords in enumerate(coordinates):\n        x, y = coords\n        data = serc_refl_xr.sel(x=x, y=y, method=\"nearest\")\n        plots.append(\n            data.hvplot.line(\n                y=\"reflectance\",\n                x=\"wavelengths\",\n                color=color_cycle,\n                label=f\"{i}\"\n            )\n        )\n        points_stream.data[\"id\"][i] = i\n    return hv.Overlay(plots)\n\ndef hover_spectra(x,y):\n    return serc_refl_xr.sel(x=x,y=y,method='nearest').hvplot.line(y='reflectance',x='wavelengths', color='black', frame_width=400)\n    # return emit_ds.sel(longitude=x,latitude=y,method='nearest').hvplot.line(y='reflectance',x='wavelengths',\n    #                                                                         color='black', frame_width=400)\n# Define the Dynamic Maps\nclick_dmap = hv.DynamicMap(click_spectra, streams=[points_stream])\nhover_dmap = hv.DynamicMap(hover_spectra, streams=[posxy])\n# Plot the Map and Dynamic Map side by side\nhv.Layout(hover_dmap*click_dmap + map * points).cols(2).opts(\n    hv.opts.Points(active_tools=['point_draw'], size=10, tools=['hover'], color='white', line_color='gray'),\n    hv.opts.Overlay(show_legend=False, show_title=False, fontscale=1.5, frame_height=480)\n)",
    "crumbs": [
      "Tutorials",
      "2 NEON - Reflectance Visualization and Classification"
    ]
  },
  {
    "objectID": "neon/02_neon-refl-classification.html#supervised-classification-using-tos-vegetation-structure-data",
    "href": "neon/02_neon-refl-classification.html#supervised-classification-using-tos-vegetation-structure-data",
    "title": "Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray",
    "section": "5. Supervised Classification Using TOS Vegetation Structure Data",
    "text": "5. Supervised Classification Using TOS Vegetation Structure Data\nIn the last part of this lesson, we’ll go over an example of how to run a supervised classification using the reflectance data along with observational “vegetation structure” data. We will create a random forest model to classify the families of trees represented in this SERC tile, using species determined from the vegetation structure data product DP1.10098.001. See the notebook Make Training Data for Species Modeling from NEON TOS Vegetation Structure Dat to learn how the vegetation structure data were pre-processed to generate the training data file. In this notebook, we will just read in this file as a starting point.\nNote that this is a quick-and-dirty example, and there are many ways you could improve the classification results, such as using more training data (this uses only data within this AOP tile), filtering out sub-optimal data (e.g. data collected in &gt; 10 % cloud cover conditions, removing outliers (e.g. due to geospatial mis-match, shadowing, or other issues), tuning the model parameters, or using a different classification algorithm.\nLet’s get started, first by exploring the training data.\n\n5.1 Read in the training data\nFirst, read in the training data csv file (called serc_2025_training_data.csv) that was generated in the previous lesson. This file contains the training data for the random forest model, including the taxonId, family, and geographic coordinates (UTM easting and northing) of the training points. Note that there was not a lot of extensive pre-processing when creating this training data, so you may want to consider ways to assess and improve the training data quality before running the model.\n\nwoody_veg_data = pd.read_csv(r\"./data/serc_training_data.csv\")\nwoody_veg_data.head()\n\nWe can use the xarray sel method to select the reflectance data corresponding to the training points. This will return an xarray dataset with the reflectance values for each band at the training point locations. As a test, let’s plot the reflectance values for the first training point, which corresponds to an American Beech tree (Fagaceae family).\n\n# Define the coordinates of the first training data pixel\neasting = woody_veg_data.iloc[0]['adjEasting']\nnorthing = woody_veg_data.iloc[0]['adjNorthing']\n\n# Extract the reflectance data from serc_refl_xr for the specified coordinates\npixel_value = serc_refl_xr.sel(x=easting, y=northing, method='nearest')\npixel_value.reflectance\n\n# Plot the reflectance values for the pixel\nplt.plot(pixel_value['wavelengths'].values.flatten(), pixel_value['reflectance'].values.flatten(), 'o');\n\nAs another test, we can plot the refletance value for one of the water bodies that shows up in the reflectance data. In the interactive plot, hover your mouse over one of the water bodies to see the UTM x, y coordinates, and then set those as the easting and northing, as shown below.\n\n# Define the coordinates of the pixel over the pool in the NW corner of the site\neasting = 364750\nnorthing = 4305180\n\n# Extract and plot the reflectance data from serc_refl_xr specified coordinates\npixel_value = serc_refl_xr.sel(x=easting, y=northing, method='nearest')\nplt.plot(pixel_value['wavelengths'].values.flatten(), pixel_value['reflectance'].values.flatten(), 'o');\n\nYou can see that the spectral signature of water is quite different from that of vegetation.\nNow that we’ve extracted the pixel value for a single pixel, we can extract the reflectance values for all of the training data points. We will loop through the rows of the training dataframe and use the xarray.Dataset.sel method to select the reflectance values of the pixels corresponding to the same geographic location as the training data points, and then we will convert this into a pandas DataFrame for use in the random forest model.\n\n\n5.2 Inspect the training data\nIt is good practice to visually inspect the spectral signatures of the training data, for example, as shown above, to make sure you are executing the code correctly, and that there aren’t any major outliers (e.g. you might catch instances of geographic mismatch between the terrestrial location and the airborne data, or if there was a shadowing effect that caused the reflectance values to be very low).\n\n# Get the wavelengths as column names for reflectance\nwavelengths = serc_refl_xr.wavelengths.values\nwavelength_cols = [f'refl_{int(wl)}' for wl in wavelengths]\n\nrecords = []\n\nfor idx, row in woody_veg_data.iterrows():\n    # Find nearest pixel in xarray\n    y_val = serc_refl_xr.y.sel(y=row['adjNorthing'], method='nearest').item()\n    x_val = serc_refl_xr.x.sel(x=row['adjEasting'], method='nearest').item()\n    # Extract reflectance spectrum\n    refl = serc_refl_xr.reflectance.sel(y=y_val, x=x_val).values\n    # Build record: taxonID, easting, northing, reflectance values\n    record = {\n        'taxonID': row['taxonID'],\n        'family': row['family'],\n        'adjEasting': row['adjEasting'],\n        'adjNorthing': row['adjNorthing'],\n    }\n    # Add reflectance values with wavelength column names\n    record.update({col: val for col, val in zip(wavelength_cols, refl)})\n    records.append(record)\n\nNow create a dataframe from these records, and display. You can see that the reflectance values are in columns named refl_381, refl_386, etc., and the family is in the family column.\n\nreflectance_df = pd.DataFrame.from_records(records)\n# display the updated dataframe, which now includes the reflectance values for all \nreflectance_df\n\nDisplay the unique taxonIDs and families represented in this training data set:\n\nreflectance_df.taxonID.unique()\n\n\nreflectance_df.family.unique()\n\nNext we can manipulate the dataframe using melt to reshape the data and make it easier to display the reflectance spectra for each family. This is a helpful first step to visualizing the data and understanding what we’re working with before getting into the classification model.\nAfter re-shaping, we can make a figure to display what the spectra look like for the different families that were recorded as part of the vegetation structure data.\n\n# Melt (re-shape) the dataframe; wavelength columns start with 'refl_'\nmelted_df = reflectance_df.melt(\n    id_vars=['family', 'adjEasting', 'adjNorthing'],\n    value_vars=[col for col in reflectance_df.columns if col.startswith('refl_')],\n    var_name='wavelength',\n    value_name='reflectance'\n)\n\n# Convert 'wavelength' from 'refl_XXX' to integer\nmelted_df['wavelength'] = melted_df['wavelength'].str.replace('refl_', '').astype(int)\n\n# Create a summary dataframe that aggregates statistics (mean, min, and max)\nsummary_df = (\n    melted_df\n    .groupby(['family', 'wavelength'])\n    .reflectance\n    .agg(['mean', 'min', 'max'])\n    .reset_index()\n)\n\nplt.figure(figsize=(12, 7))\n\n# Create a color palette\npalette = sns.color_palette('hls', n_colors=summary_df['family'].nunique())\n\n# Plot the mean reflectance spectra for each family, filling with semi-transparent color between the min and max value\nfor i, (family, group) in enumerate(summary_df.groupby('family')):\n    # print(family)\n    if family in ['Fagaceae','Magnoliaceae','Hamamelidaceae','Juglandaceae','Aceraceae']:\n    # Plot mean line\n        plt.plot(group['wavelength'], group['mean'], label=family, color=palette[i])\n        # Plot min-max fill\n        plt.fill_between(\n            group['wavelength'],\n            group['min'],\n            group['max'],\n            color=palette[i],\n            alpha=0.2\n        )\n\nplt.xlabel('Wavelength')\nplt.ylabel('Reflectance')\nplt.title('Average Reflectance Spectra by Family \\n (with Min/Max Range)')\nplt.legend(title='family')\nplt.tight_layout()\nplt.show()\n\nWe can see that the spectral signatures for the different families have similar shapes, and there is a decent amount of spread in the reflectance values for each family. Some of this spread may be due to the cloud conditions during the time of acquisition. Reflectance values of one species may vary depending on how cloudy it was, or whether there was a cloud obscuring the sun during the collection. The random forest model may not be able to fully distinguish between the different families based on their spectral signatures, but we will see!\n\n\n5.3 Set up the Random Forest Model to Classify Tree Families\nWe can set up our random forest model by following the steps below:\n\nPrepare the training data by dropping the family column and setting the family column as the target variable. Remove the bad bands (NaN) from the reflectance predictor variables.\nSplit the data into training and testing sets.\nTrain the random forest model on the training data.\nEvaluate the model on the testing data.\nVisualize the results.\n\nWe will need to import scikit-learn (sklearn) packages in order to run the random forest model. If you don’t have these packages installed, you can install them using !pip install scikit-learn.\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\n\n\n5.4 Prepare and clean the training data\n\n# 1. Prepare the Data\n# Identify reflectance columns\nrefl_cols = [col for col in reflectance_df.columns if col.startswith('refl_')]\n\n# Remove rows with any NaN in reflectance columns (these are the 'bad bands')\nclean_df = reflectance_df.dropna(axis=1)\n# re-define refl_columns after removing the ones that are all NaN\nrefl_cols = [col for col in clean_df.columns if col.startswith('refl_')]\n\n\n# display the cleaned dataframe\nclean_df\n\nNote that we have &gt; 360 predictor variables (reflectance values for each band), and only 100 training points, so the model may not perform very well, due to over fitting. You can try increasing the number of training points by using more of the training data, or by using a different classification algorithm. Recall that we just pulled woody vegetation data from this tile that covers the tower, and there are also data collected throughout the rest of the TOS terrestrial sampling plots, so you could pull in more training data from the other tiles as well. You would likely not need all of the reflectance bands - for example, you could take every 2nd or 3rd band, or perform a PCA to reduce the number of bands. These are all things you could test as part of your model. For this lesson, we will include all of the valid reflectance bands for the sake of simplicity.\nThat said, we will need to remove some of the families that are poorly represented in the training data, as they will not be able to be predicted by the model. We can do this by filtering out families that have less than 10 training points. If you leave these in, the model will not be able to predict them, and will return an error when you try to evaluate the model.\n\n# determine the number of training data points for each family\nclean_df[['taxonID','family']].groupby('family').count().sort_values('taxonID', ascending=False)\n\n\n# Remove the rows where there are fewer than 10 samples\n# List of families to remove\nfamilies_to_remove = ['Rosaceae', 'Pinaceae', 'Ulmaceae']\n\n# Remove rows where family is in the families_to_remove list\nclean_df = clean_df[~clean_df['family'].isin(families_to_remove)].copy()\n\n\n\n5.5 Encode the target variable\nNext we need to encode the target variable (family) as integers, so that the model can work properly. Encoding is the process of converting from human-readable text (words / characters) to the byte representations used by computers. We can do this using the LabelEncoder from scikit-learn.\n\n# Encode the Target Variable (family)\n# Machine learning models require numeric targets. Use LabelEncoder:\nle = LabelEncoder()\nclean_df['family_encoded'] = le.fit_transform(clean_df['family'])\n# Display the cleaned dataframe after encoding the target variable\nclean_df[['taxonID','family','family_encoded','adjEasting','adjNorthing','refl_381','refl_2461']].head()\n\n\n# Confirm that the number of unique encodings is the same as the number of unique families, as a sanity check\nclean_df['family_encoded'].nunique()\n\n\n\n5.6 Split the data into training and testing sets\nIn this next step, we will split the data into training and testing sets. We will use 80% of the data for training and 20% for testing (this is the default split). This is a common practice in machine learning to test the performance of the model, and to ensure that the model is able to generalize to new data (e.g. you’re not over-fitting).\n\n# Split Data into Train/Test Sets\nX = clean_df[refl_cols].values\ny = clean_df['family_encoded'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n\n\n\n5.7 Create a Random Forest Classifier Object\n\n# Create a Random Forest Classifier object and fit it to the training data\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\nclf.fit(X_train, y_train)\n\n\n\n5.8 Evaluate the Model\n\n# Determine the accuracy scores based off of the test set\ny_pred = clf.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred, target_names=le.classes_))\n\nWhat do these accuracy metrics mean?\n\nPrecision: Of the items predicted as a given class, what fraction were actually that class?\n(Precision = True Positives / (True Positives + False Positives))\nRecall: Of all actual items of a given class, what fraction were correctly predicted?\n(Recall = True Positives / (True Positives + False Negatives))\nF1-score: The harmonic mean of precision and recall. It balances both metrics.\n(F1 = 2 * (Precision * Recall) / (Precision + Recall))\nSupport: The number of true instances of each class in the dataset (i.e., how many samples belong to each class).\n\nThese metrics are commonly used to evaluate classification models. Ideally we would be closer to 1 for the precision, recall, and f1-scores, which would indicate that the model is performing well. The support values indicate how many training points were used for each family, and you can see that some families have very few training points, which is likely negatively impacting the model performance.",
    "crumbs": [
      "Tutorials",
      "2 NEON - Reflectance Visualization and Classification"
    ]
  },
  {
    "objectID": "neon/02_neon-refl-classification.html#discussion",
    "href": "neon/02_neon-refl-classification.html#discussion",
    "title": "Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray",
    "section": "Discussion",
    "text": "Discussion\nGreat job! You now should have a fairly good grasp on working with NEON airborne and field datasets together.\nWhat are some things you could do to improve the classification results?\nModels are only as good as the underlying training data - so the better the training data (more + higher quality training data points) the better your results will be.\nYou could consider some of the following options:\n\nIncrease the number of training points: Use more training data from the other plots (and use more AOP tiles). You could also collect your own additional data within the NEON site.\nFilter out sub-optimal data: Remove training points that were collected in poor weather conditions (e.g. &gt; 10% cloud cover), or that are outliers (e.g. due to spatial mis-match, shadowing, or other issues).\nAverage the reflectance values over an entire tree crown: In this example, we just pulled the reflectance values from a single pixel, but you could average the reflectance values over an entire tree crown to get a more representative value for each tree. If part of the tree is in shadow, you may want to remove that pixel from the average.\nTune the model parameters: You can adjust the hyperparameters of the random forest model, such as the number of trees, maximum depth, and minimum samples per leaf, to improve performance.\nUse a different classification algorithm: Random forest is a good starting point, but you could also try other algorithms such as support vector machines, gradient boosting, or neural networks to see if they perform better.",
    "crumbs": [
      "Tutorials",
      "2 NEON - Reflectance Visualization and Classification"
    ]
  },
  {
    "objectID": "neon/02_neon-refl-classification.html#next-steps",
    "href": "neon/02_neon-refl-classification.html#next-steps",
    "title": "Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray",
    "section": "Next Steps",
    "text": "Next Steps\nIn this example, we just scratched the surface of what you can do with NEON reflectance data. Here are some next steps you could take to further explore and analyze the data:\n\nApply the model to the entire reflectance dataset: Use the trained model to predict the tree families for all pixels in the reflectance dataset, and visualize the results. You may wish to include more training data for non-tree species, since the AOP data also captures non-vegetation such as water bodies, buildings, roads, etc.\nTry out the same model on SERC AOP data that was acquired in better weather conditions: Use the reflectance data from SERC 2017, which was collected in clearer weather conditions, to see if the model performs better. Note that you may need to make some minor modifications to the aop_h5refl2xarray function to accommodate the slightly different data structure of the directional reflectance data product (2019 data is not yet available with BRDF and topographic corrections, as of August 2025).\nExplore other NEON sites: Use the neonutilities package to explore reflectance data from other NEON sites, and compare the spectral signatures of different land cover types.\nAdd in other NEON AOP datasets: In this lesson, we only looked at the reflectance data. How might other NEON data products compliment this analysis? For example, you could look at the lidar data to get information about the structure of the vegetation, for example the Canopy Height Model (CHM) or the Digital Surface Model (DSM). You could also look at the AOP imagery data.\nUse the reflectance data for other applications: The reflectance data can be used for a variety of applications, such as mapping vegetation health, detecting disease or invasive species, and mapping droughts, wildfires, or other natural disturbances and their impacts. You could use a similar approach to explore some of these applications.\n\n\n# Example Challenge Solution: Apply the model to the full AOP reflectance data tile at SERC\n\n# 1. Prepare the data:\n\n# Extract the reflectance array from your xarray Dataset:\nrefl = serc_refl_xr['reflectance'].values  # shape: (y, x, bands)\n# Remove the bad bands so that we can apply the model, which only uses 363 bands\ngood_bands = serc_refl_xr['good_wavelengths'].values.astype(bool)\nrefl_good = refl[:, :, good_bands]         # shape: (y, x, n_good_bands)\n\n# 2. Reshape for prediction:\nnrows, ncols, nbands = refl_good.shape\nrefl_2d = refl_good.reshape(-1, nbands)\n\n# 3. Apply the model:\n# Use the trained random forest model (e.g., rf_model) to predict values for every pixel\npreds = clf.predict(refl_2d)\n\n# 4. Reshape predictions back to image (y, x):\npred_map = preds.reshape(nrows, ncols)\n\n# 5. Create an xarray DataArray for mapping, using the coordinates from your original data:\npred_xr = xr.DataArray(\n    pred_map,\n    dims=('y', 'x'),\n    coords={'y': serc_refl_xr['y'], 'x': serc_refl_xr['x']},\n    name='classification_prediction'\n)\n\n# 6. Plot the map, using hvplot to visualize:\n# pred_xr.hvplot.image(x='x', y='y', cmap='tab20', title='Random Forest Classification Map')\n\n\nclasses = le.classes_\nprint('classes:', classes)\n\nclass_labels = dict(enumerate(classes))\nprint('class labels:',class_labels)\n\n\n# Convert your prediction DataArray to a categorical type with labels:\npred_xr_labeled = pred_xr.copy()\npred_xr_labeled = pred_xr_labeled.assign_coords(\n    family=(('y', 'x'), np.vectorize(class_labels.get)(pred_xr.values))\n)\n\n\n# Plot the classification map, using hvplot to visualize:\nfrom matplotlib.colors import ListedColormap, BoundaryNorm\n# Plot using hvplot with the family coordinate as the color dimension:\n\nfamily_codes = np.arange(7)\nfamily_names = classes\n# Choose 7 distinct colors (can use tab10, Set1, or your own)\ncolors = plt.get_cmap('tab10').colors[:7]  # 7 distinct colors from tab10\n\n# Create a mapping from code to color\ncode_to_color = {code: colors[i] for i, code in enumerate(family_codes)}\n\ncmap = ListedColormap([code_to_color[code] for code in family_codes])\n\npred_xr_labeled.hvplot.image(\n    x='x', y='y', groupby=[], color='family', cmap=cmap,\n    title='Random Forest Classification Map', frame_width=600, frame_height=600\n).opts(xformatter='%.0f', yformatter='%.0f')\n\n\n# Optional: Create a custom colorbar for the classification map\nfrom matplotlib.colors import ListedColormap, BoundaryNorm\n\nfig, ax = plt.subplots(figsize=(6, 1))\nfig.subplots_adjust(bottom=0.5)\n\n# Create a colormap and norm\ncmap = ListedColormap([code_to_color[code] for code in family_codes])\nnorm = BoundaryNorm(np.arange(-0.5, 7.5, 1), cmap.N)\n\n# Create colorbar\ncb = plt.colorbar(\n    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n    cax=ax, orientation='horizontal', ticks=family_codes\n)\ncb.ax.set_xticklabels(family_names,fontsize=6)\ncb.set_label('Family')\nplt.show()\n\n\nAcknowledgements\nMuch of this tutorial was inspired by and adapated from lessons in the NASA VITALS GitHub Repository. Thank you!",
    "crumbs": [
      "Tutorials",
      "2 NEON - Reflectance Visualization and Classification"
    ]
  },
  {
    "objectID": "resources/additional_resources.html",
    "href": "resources/additional_resources.html",
    "title": "Additional Resources",
    "section": "",
    "text": "We recommend the following tutorial series and tutorials for working with NEON AOP data. These provide example workflows at a range of levels from beginner to intermediate/advanced, in various programming languages including Python, R, and Google Earth Engine (JavaScript and Python).\n\n\n\nIntroduction to Hyperspectral Remote Sensing Data in Python\nNotebooks for working with NEON and EMIT Hyperspectral Data\n\n\n\n\n\nIntroduction to Hyperspectral Remote Sensing Data in R\nIntroduction to Light Detection and Ranging (LiDAR) in R\n\n\n\n\n\nDownload and Explore NEON Data\nUsing an API Token when Accessing NEON Data with neonUtilities\nCompare tree height measured from the ground to a Lidar-based Canopy Height Model\n\n\n\n\nNEON GEE Publisher Catalog\n\n\n\nIntro to AOP Data in Google Earth Engine (GEE) Tutorial Series\nRandom Forest Species Classification using AOP and TOS data in GEE\nPrincipal Component Analysis of AOP Hyperspectral Data in GEE\n\n\n\n\n\nIntro to AOP Datasets in Google Earth Engine (GEE) using Python\nIntro to AOP Hyperspectral Data in Google Earth Engine (GEE) using Python geemap\nExploring NEON AOP remote sensing and GBIF occurrence data in Google Earth Engine Python (geemap) to assess the impacts of a wildfire",
    "crumbs": [
      "Resources",
      "Additional Resources"
    ]
  },
  {
    "objectID": "resources/additional_resources.html#neon",
    "href": "resources/additional_resources.html#neon",
    "title": "Additional Resources",
    "section": "",
    "text": "We recommend the following tutorial series and tutorials for working with NEON AOP data. These provide example workflows at a range of levels from beginner to intermediate/advanced, in various programming languages including Python, R, and Google Earth Engine (JavaScript and Python).\n\n\n\nIntroduction to Hyperspectral Remote Sensing Data in Python\nNotebooks for working with NEON and EMIT Hyperspectral Data\n\n\n\n\n\nIntroduction to Hyperspectral Remote Sensing Data in R\nIntroduction to Light Detection and Ranging (LiDAR) in R\n\n\n\n\n\nDownload and Explore NEON Data\nUsing an API Token when Accessing NEON Data with neonUtilities\nCompare tree height measured from the ground to a Lidar-based Canopy Height Model\n\n\n\n\nNEON GEE Publisher Catalog\n\n\n\nIntro to AOP Data in Google Earth Engine (GEE) Tutorial Series\nRandom Forest Species Classification using AOP and TOS data in GEE\nPrincipal Component Analysis of AOP Hyperspectral Data in GEE\n\n\n\n\n\nIntro to AOP Datasets in Google Earth Engine (GEE) using Python\nIntro to AOP Hyperspectral Data in Google Earth Engine (GEE) using Python geemap\nExploring NEON AOP remote sensing and GBIF occurrence data in Google Earth Engine Python (geemap) to assess the impacts of a wildfire",
    "crumbs": [
      "Resources",
      "Additional Resources"
    ]
  },
  {
    "objectID": "resources/additional_resources.html#nasa-airborne-and-more",
    "href": "resources/additional_resources.html#nasa-airborne-and-more",
    "title": "Additional Resources",
    "section": "NASA Airborne (and more!)",
    "text": "NASA Airborne (and more!)\n\nAirborne and Field Data Resource Center\nNASA Airborne Science Data Tutorials\nBioSCape Campaign\nSHIFT Campaign\nVSWIR Imaging and Thermal Applications, Learning, and Science Repository (VITALS)",
    "crumbs": [
      "Resources",
      "Additional Resources"
    ]
  },
  {
    "objectID": "setup/setup_instructions.html",
    "href": "setup/setup_instructions.html",
    "title": "Repository Setup Instructions",
    "section": "",
    "text": "The how-tos and tutorials in this repository require a NASA Earthdata account, an installation of Git, and a compatible Python Environment. Resources in this repository have been developed using the Openscapes 2i2c JupyterHub cloud workspace.\nFor local Python environment setup we recommend using mamba to manage Python packages. To install mamba, download miniforge for your operating system. If using Windows, be sure to check the box to “Add mamba to my PATH environment variable” to enable use of mamba directly from your command line interface. Note that this may cause an issue if you have an existing mamba install through Anaconda.\n\n\nThese Python Environments will work for all of the guides, how-to’s, and tutorials within this repository.\n\nUsing your preferred command line interface (command prompt, terminal, cmder, etc.) navigate to your local copy of the repository, then type the following to create a compatible Python environment.\nFor Windows:\nmamba create -n ornl_daac_neon -c conda-forge --yes python=3.10 fiona=1.8.22 gdal hvplot geoviews rioxarray rasterio jupyter geopandas earthaccess jupyter_bokeh h5py h5netcdf spectral scikit-image jupyterlab seaborn dask ray-default\nFor MacOSX:\nmamba create -n ornl_daac_neon -c conda-forge --yes python=3.10 gdal=3.7.2 hvplot geoviews rioxarray rasterio geopandas fiona=1.9.4 jupyter earthaccess jupyter_bokeh h5py h5netcdf spectral scikit-image seaborn jupyterlab dask ray-default ray-dashboard\nNext, activate the Python Environment that you just created.\nmamba activate ornl_daac_neon\nNow you can launch Jupyter Notebook to open the notebooks included.\njupyter notebook \n\nStill having trouble getting a compatible Python environment set up? Contact ORNL DAAC User Services."
  },
  {
    "objectID": "setup/setup_instructions.html#python-environment-setup",
    "href": "setup/setup_instructions.html#python-environment-setup",
    "title": "Repository Setup Instructions",
    "section": "",
    "text": "These Python Environments will work for all of the guides, how-to’s, and tutorials within this repository.\n\nUsing your preferred command line interface (command prompt, terminal, cmder, etc.) navigate to your local copy of the repository, then type the following to create a compatible Python environment.\nFor Windows:\nmamba create -n ornl_daac_neon -c conda-forge --yes python=3.10 fiona=1.8.22 gdal hvplot geoviews rioxarray rasterio jupyter geopandas earthaccess jupyter_bokeh h5py h5netcdf spectral scikit-image jupyterlab seaborn dask ray-default\nFor MacOSX:\nmamba create -n ornl_daac_neon -c conda-forge --yes python=3.10 gdal=3.7.2 hvplot geoviews rioxarray rasterio geopandas fiona=1.9.4 jupyter earthaccess jupyter_bokeh h5py h5netcdf spectral scikit-image seaborn jupyterlab dask ray-default ray-dashboard\nNext, activate the Python Environment that you just created.\nmamba activate ornl_daac_neon\nNow you can launch Jupyter Notebook to open the notebooks included.\njupyter notebook \n\nStill having trouble getting a compatible Python environment set up? Contact ORNL DAAC User Services."
  }
]